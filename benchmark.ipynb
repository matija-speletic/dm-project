{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.lunar import LUNAR\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = './benchad_datasets/'\n",
    "\n",
    "datasets = []\n",
    "dataset_names = []\n",
    "for root, _, filenames in os.walk(folder_path):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        datasets.append(np.load(file_path))\n",
    "        dataset_names.append(filename.split('_')[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Dataset', '# Samples', '# Features', 'Anomaly Ratio',\n",
    "                                'ABOD Precision', 'ABOD AUC', 'ABOD Time',\n",
    "                                'LOF Precision', 'LOF AUC', 'LOF Time',\n",
    "                                'iForest Precision', 'iForest AUC', 'iForest Time',\n",
    "                                'AutoEncoder Precision', 'AutoEncoder AUC', 'AutoEncoder Time',\n",
    "                                'LUNAR Precision', 'LUNAR AUC', 'LUNAR Time'])\n",
    "algorithms = {\n",
    "    'ABOD': ABOD,\n",
    "    'LOF': LOF,\n",
    "    'iForest': IForest,\n",
    "    'AutoEncoder': AutoEncoder,\n",
    "    'LUNAR': LUNAR\n",
    "}\n",
    "unsupervised_algorithms = ['ABOD', 'LOF', 'iForest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_unsupervised_algorithm(algorithm, X,  y):\n",
    "    clf = algorithm(contamination=np.mean(y))\n",
    "\n",
    "    start_time = time.time()\n",
    "    clf.fit(X)\n",
    "    test_scores = clf.decision_function(X)\n",
    "    end_time = time.time()\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    precision = round(precision_score(y, y_pred), ndigits=4)\n",
    "    auc = round(roc_auc_score(y, test_scores), ndigits=4)\n",
    "    duration = round(end_time - start_time, ndigits=4)\n",
    "    return precision, auc, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_semi_supervised_algorithm(algorithm, X, y):\n",
    "    if algorithm is AutoEncoder:\n",
    "        print('AutoEncoder')\n",
    "        clf = algorithm(\n",
    "            hidden_neurons=[16, 16, 4, 16, 16], epochs=5, contamination=np.mean(y))\n",
    "    else:\n",
    "        clf = algorithm(contamination=np.mean(y))\n",
    "\n",
    "    X_normal = X[y == 0]\n",
    "    X_anomaly = X[y == 1]\n",
    "\n",
    "    random_indices = np.random.choice(\n",
    "        len(X_normal), size=len(X_anomaly), replace=False)\n",
    "    array1 = X_normal[random_indices]\n",
    "    X_train = np.delete(X_normal, random_indices, axis=0)\n",
    "    X_test = np.concatenate((X_anomaly, array1), axis=0)\n",
    "    y_test = np.concatenate(\n",
    "        (np.ones(len(X_anomaly)), np.zeros(len(array1))), axis=0)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(X_train.shape, X_test.shape, y_test.shape)\n",
    "    clf.fit(X_train)\n",
    "    test_scores = clf.decision_function(X_test)\n",
    "    end_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    precision = round(precision_score(y_test, y_pred), ndigits=4)\n",
    "    auc = round(roc_auc_score(y_test, test_scores), ndigits=4)\n",
    "    duration = round(end_time - start_time, ndigits=4)\n",
    "    return precision, auc, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ABOD on fault...\n",
      "Running LOF on fault...\n",
      "Running iForest on fault...\n",
      "Running AutoEncoder on fault...\n",
      "AutoEncoder\n",
      "(595, 27) (1346, 27) (1346,)\n",
      "WARNING:tensorflow:From c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 27)                756       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 27)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                756       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 27)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                448       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 27)                459       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3111 (12.15 KB)\n",
      "Trainable params: 3111 (12.15 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "17/17 [==============================] - 2s 18ms/step - loss: 4.9932 - val_loss: 3.7462\n",
      "Epoch 2/5\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.6810 - val_loss: 3.2337\n",
      "Epoch 3/5\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.1627 - val_loss: 2.9057\n",
      "Epoch 4/5\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.8659 - val_loss: 2.6717\n",
      "Epoch 5/5\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.6510 - val_loss: 2.4905\n",
      "19/19 [==============================] - 0s 896us/step\n",
      "43/43 [==============================] - 0s 756us/step\n",
      "43/43 [==============================] - 0s 753us/step\n",
      "Running LUNAR on fault...\n",
      "(595, 27) (1346, 27) (1346,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ABOD on glass...\n",
      "Running LOF on glass...\n",
      "Running iForest on glass...\n",
      "Running AutoEncoder on glass...\n",
      "AutoEncoder\n",
      "(196, 7) (18, 7) (18,)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                128       \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1051 (4.11 KB)\n",
      "Trainable params: 1051 (4.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 2s 45ms/step - loss: 2.0579 - val_loss: 1.4474\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9924 - val_loss: 1.4266\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9854 - val_loss: 1.4067\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9121 - val_loss: 1.3878\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8802 - val_loss: 1.3697\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Running LUNAR on glass...\n",
      "(196, 7) (18, 7) (18,)\n",
      "Running ABOD on Hepatitis...\n",
      "Running LOF on Hepatitis...\n",
      "Running iForest on Hepatitis...\n",
      "Running AutoEncoder on Hepatitis...\n",
      "AutoEncoder\n",
      "(54, 19) (26, 19) (26,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 19)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 19)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 16)                320       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 19)                323       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2095 (8.18 KB)\n",
      "Trainable params: 2095 (8.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 2s 226ms/step - loss: 3.6039 - val_loss: 2.3110\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.6989 - val_loss: 2.2797\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.5757 - val_loss: 2.2507\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.4375 - val_loss: 2.2237\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.4768 - val_loss: 2.1981\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Running LUNAR on Hepatitis...\n",
      "(54, 19) (26, 19) (26,)\n",
      "Running ABOD on InternetAds...\n",
      "Running LOF on InternetAds...\n",
      "Running iForest on InternetAds...\n",
      "Running AutoEncoder on InternetAds...\n",
      "AutoEncoder\n",
      "(1230, 1555) (736, 1555) (736,)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 1555)              2419580   \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 1555)              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1555)              2419580   \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 1555)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 16)                24896     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1555)              26435     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4891183 (18.66 MB)\n",
      "Trainable params: 4891183 (18.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "35/35 [==============================] - 3s 33ms/step - loss: 233.6985 - val_loss: 561.5266\n",
      "Epoch 2/5\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 165.0321 - val_loss: 1502.7577\n",
      "Epoch 3/5\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 88.9259 - val_loss: 2660.6111\n",
      "Epoch 4/5\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 46.5571 - val_loss: 3909.3364\n",
      "Epoch 5/5\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 26.6170 - val_loss: 5296.0903\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "Running LUNAR on InternetAds...\n",
      "(1230, 1555) (736, 1555) (736,)\n",
      "Running ABOD on Ionosphere...\n",
      "Running LOF on Ionosphere...\n",
      "Running iForest on Ionosphere...\n",
      "Running AutoEncoder on Ionosphere...\n",
      "AutoEncoder\n",
      "(99, 32) (252, 32) (252,)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3876 (15.14 KB)\n",
      "Trainable params: 3876 (15.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 2s 113ms/step - loss: 5.0971 - val_loss: 6.5523\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 4.4300 - val_loss: 6.0592\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 4.1883 - val_loss: 5.6231\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.9184 - val_loss: 5.2685\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.6728 - val_loss: 4.9602\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 975us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on Ionosphere...\n",
      "(99, 32) (252, 32) (252,)\n",
      "Running ABOD on landsat...\n",
      "Running LOF on landsat...\n",
      "Running iForest on landsat...\n",
      "Running AutoEncoder on landsat...\n",
      "AutoEncoder\n",
      "(3769, 36) (2666, 36) (2666,)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 36)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 36)                0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 16)                592       \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 36)                612       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4560 (17.81 KB)\n",
      "Trainable params: 4560 (17.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "106/106 [==============================] - 2s 4ms/step - loss: 2.6074 - val_loss: 1.8452\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6221 - val_loss: 1.4624\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.3874 - val_loss: 1.3278\n",
      "Epoch 4/5\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.2880 - val_loss: 1.2580\n",
      "Epoch 5/5\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.2320 - val_loss: 1.2149\n",
      "118/118 [==============================] - 0s 711us/step\n",
      "84/84 [==============================] - 0s 770us/step\n",
      "84/84 [==============================] - 0s 789us/step\n",
      "Running LUNAR on landsat...\n",
      "(3769, 36) (2666, 36) (2666,)\n",
      "Running ABOD on mnist...\n",
      "Running LOF on mnist...\n",
      "Running iForest on mnist...\n",
      "Running AutoEncoder on mnist...\n",
      "AutoEncoder\n",
      "(6203, 100) (1400, 100) (1400,)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 16)                1616      \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 100)               1700      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24208 (94.56 KB)\n",
      "Trainable params: 24208 (94.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 3s 3ms/step - loss: 5.1944 - val_loss: 2.1286\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 2.4911 - val_loss: 1.3477\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 1.9527 - val_loss: 1.0864\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 1.6539 - val_loss: 0.9662\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 1.4595 - val_loss: 0.8944\n",
      "194/194 [==============================] - 0s 795us/step\n",
      "44/44 [==============================] - 0s 792us/step\n",
      "44/44 [==============================] - 0s 784us/step\n",
      "Running LUNAR on mnist...\n",
      "(6203, 100) (1400, 100) (1400,)\n",
      "Running ABOD on musk...\n",
      "Running LOF on musk...\n",
      "Running iForest on musk...\n",
      "Running AutoEncoder on musk...\n",
      "AutoEncoder\n",
      "(2868, 166) (194, 166) (194,)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 166)               27722     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 166)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 166)               27722     \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 166)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 16)                2672      \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 166)               2822      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61630 (240.74 KB)\n",
      "Trainable params: 61630 (240.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "81/81 [==============================] - 2s 5ms/step - loss: 8.2865 - val_loss: 5.4751\n",
      "Epoch 2/5\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 3.6492 - val_loss: 2.3727\n",
      "Epoch 3/5\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 2.1088 - val_loss: 1.8260\n",
      "Epoch 4/5\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 1.7367 - val_loss: 1.6106\n",
      "Epoch 5/5\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 1.5657 - val_loss: 1.4904\n",
      "90/90 [==============================] - 0s 810us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1000us/step\n",
      "Running LUNAR on musk...\n",
      "(2868, 166) (194, 166) (194,)\n",
      "Running ABOD on Cardiotocography...\n",
      "Running LOF on Cardiotocography...\n",
      "Running iForest on Cardiotocography...\n",
      "Running AutoEncoder on Cardiotocography...\n",
      "AutoEncoder\n",
      "(1182, 21) (932, 21) (932,)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_64 (Dense)            (None, 21)                462       \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 21)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 21)                462       \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 21)                0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 16)                352       \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 21)                357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2325 (9.08 KB)\n",
      "Trainable params: 2325 (9.08 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "34/34 [==============================] - 2s 8ms/step - loss: 3.2650 - val_loss: 3.2276\n",
      "Epoch 2/5\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2.4906 - val_loss: 2.7045\n",
      "Epoch 3/5\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2.0682 - val_loss: 2.3161\n",
      "Epoch 4/5\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.7771 - val_loss: 2.0659\n",
      "Epoch 5/5\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.5938 - val_loss: 1.9066\n",
      "37/37 [==============================] - 0s 817us/step\n",
      "30/30 [==============================] - 0s 690us/step\n",
      "30/30 [==============================] - 0s 808us/step\n",
      "Running LUNAR on Cardiotocography...\n",
      "(1182, 21) (932, 21) (932,)\n"
     ]
    }
   ],
   "source": [
    "for i, (dataset, dataset_name) in enumerate(zip(datasets, dataset_names)):\n",
    "    X = dataset['X']\n",
    "    y = dataset['y']\n",
    "    anomaly_ratio = np.mean(y)*100\n",
    "\n",
    "    for name, algorithm in algorithms.items():\n",
    "        print(f\"Running {name} on {dataset_name}...\")\n",
    "        if name in unsupervised_algorithms:\n",
    "            precision, auc, exec_time = evaluate_unsupervised_algorithm(\n",
    "                algorithm, X, y)\n",
    "        else:\n",
    "            precision, auc, exec_time = evaluate_semi_supervised_algorithm(\n",
    "                algorithm, X, y)\n",
    "        results.loc[i, f'{name} Precision'] = precision\n",
    "        results.loc[i, f'{name} AUC'] = auc\n",
    "        results.loc[i, f'{name} Time'] = exec_time\n",
    "\n",
    "    results.loc[i, 'Dataset'] = dataset_name\n",
    "    results.loc[i, '# Samples'] = X.shape[0]\n",
    "    results.loc[i, '# Features'] = X.shape[1]\n",
    "    results.loc[i, 'Anomaly Ratio'] = anomaly_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th># Samples</th>\n",
       "      <th># Features</th>\n",
       "      <th>Anomaly Ratio</th>\n",
       "      <th>ABOD Precision</th>\n",
       "      <th>ABOD AUC</th>\n",
       "      <th>ABOD Time</th>\n",
       "      <th>LOF Precision</th>\n",
       "      <th>LOF AUC</th>\n",
       "      <th>LOF Time</th>\n",
       "      <th>iForest Precision</th>\n",
       "      <th>iForest AUC</th>\n",
       "      <th>iForest Time</th>\n",
       "      <th>AutoEncoder Precision</th>\n",
       "      <th>AutoEncoder AUC</th>\n",
       "      <th>AutoEncoder Time</th>\n",
       "      <th>LUNAR Precision</th>\n",
       "      <th>LUNAR AUC</th>\n",
       "      <th>LUNAR Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fault</td>\n",
       "      <td>1941</td>\n",
       "      <td>27</td>\n",
       "      <td>34.672849</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.6986</td>\n",
       "      <td>1.5692</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.5749</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>5.2817</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.8092</td>\n",
       "      <td>4.2711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glass</td>\n",
       "      <td>214</td>\n",
       "      <td>7</td>\n",
       "      <td>4.205607</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.8157</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>2.7349</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>1.6424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hepatitis</td>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.4788</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>2.7512</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>1.2779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InternetAds</td>\n",
       "      <td>1966</td>\n",
       "      <td>1555</td>\n",
       "      <td>18.71821</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.6299</td>\n",
       "      <td>5.437</td>\n",
       "      <td>0.4073</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.1689</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>7.1861</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>4.9923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ionosphere</td>\n",
       "      <td>351</td>\n",
       "      <td>32</td>\n",
       "      <td>35.897436</td>\n",
       "      <td>0.8092</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.6455</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>2.7592</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>1.8464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>landsat</td>\n",
       "      <td>6435</td>\n",
       "      <td>36</td>\n",
       "      <td>20.714841</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>1.6365</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.4587</td>\n",
       "      <td>3.1605</td>\n",
       "      <td>0.8536</td>\n",
       "      <td>0.7902</td>\n",
       "      <td>12.2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mnist</td>\n",
       "      <td>7603</td>\n",
       "      <td>100</td>\n",
       "      <td>9.206892</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>6.915</td>\n",
       "      <td>0.2454</td>\n",
       "      <td>0.6449</td>\n",
       "      <td>0.2347</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.2018</td>\n",
       "      <td>0.8715</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>4.6273</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>19.9083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>musk</td>\n",
       "      <td>3062</td>\n",
       "      <td>166</td>\n",
       "      <td>3.167864</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>1.5429</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.4124</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2882</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.3589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cardiotocography</td>\n",
       "      <td>2114</td>\n",
       "      <td>21</td>\n",
       "      <td>22.043519</td>\n",
       "      <td>0.2869</td>\n",
       "      <td>0.5553</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.4292</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>3.0573</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>0.8081</td>\n",
       "      <td>4.6133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Dataset # Samples # Features Anomaly Ratio ABOD Precision  \\\n",
       "0             fault      1941         27     34.672849         0.5035   \n",
       "1             glass       214          7      4.205607         0.1818   \n",
       "2         Hepatitis        80         19         16.25         0.1429   \n",
       "3       InternetAds      1966       1555      18.71821         0.2879   \n",
       "4        Ionosphere       351         32     35.897436         0.8092   \n",
       "5           landsat      6435         36     20.714841         0.2198   \n",
       "6             mnist      7603        100      9.206892         0.2383   \n",
       "7              musk      3062        166      3.167864         0.0094   \n",
       "8  Cardiotocography      2114         21     22.043519         0.2869   \n",
       "\n",
       "  ABOD AUC ABOD Time LOF Precision LOF AUC LOF Time iForest Precision  \\\n",
       "0   0.6986    1.5692         0.423  0.5957     0.02            0.4264   \n",
       "1    0.845     0.047         0.125  0.8157    0.004            0.1111   \n",
       "2   0.4788    0.0204        0.3333   0.589    0.012            0.1538   \n",
       "3   0.6299     5.437        0.4073  0.6451   0.1426             0.462   \n",
       "4    0.927    0.0753        0.7886  0.8603   0.0199            0.6667   \n",
       "5   0.5025    1.6365        0.2778  0.5466    0.116            0.2198   \n",
       "6   0.7005     6.915        0.2454  0.6449   0.2347            0.2857   \n",
       "7   0.0528    1.5429        0.0469  0.4124   0.0605               1.0   \n",
       "8   0.5553    0.4172        0.3364  0.5965   0.0223            0.4292   \n",
       "\n",
       "  iForest AUC iForest Time AutoEncoder Precision AutoEncoder AUC  \\\n",
       "0      0.5629       0.1145                0.5749          0.5391   \n",
       "1      0.7626       0.0945                   0.5          0.7901   \n",
       "2      0.7049       0.1091                 0.875          0.8047   \n",
       "3      0.6895       0.1689                0.7879          0.7993   \n",
       "4      0.8383       0.1125                0.6455          0.8825   \n",
       "5       0.491       0.1618                0.5355          0.4587   \n",
       "6      0.7885       0.2018                0.8715          0.9087   \n",
       "7         1.0       0.1309                 0.951             1.0   \n",
       "8      0.7172       0.1181                 0.747          0.8178   \n",
       "\n",
       "  AutoEncoder Time LUNAR Precision LUNAR AUC LUNAR Time  \n",
       "0           5.2817          0.7883    0.8092     4.2711  \n",
       "1           2.7349             0.5    0.9012     1.6424  \n",
       "2           2.7512          0.6364    0.7515     1.2779  \n",
       "3           7.1861          0.8924    0.8628     4.9923  \n",
       "4           2.7592          0.7396    0.9828     1.8464  \n",
       "5           3.1605          0.8536    0.7902    12.2003  \n",
       "6           4.6273          0.9422    0.9333    19.9083  \n",
       "7           3.2882          0.9798       1.0     9.3589  \n",
       "8           3.0573          0.8517    0.8081     4.6133  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv('results.csv', index=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETRAN Rad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Dataset', '# Samples', '# Features', 'Anomaly Ratio',\n",
    "                                'iForest Precision', 'iForest AUC', 'iForest Accuracy', 'iForest Recall', 'iForest F1 Score',\n",
    "                                'iForest Fit Time', 'iForest Score Time',\n",
    "                                'AutoEncoder Precision', 'AutoEncoder AUC', 'AutoEncoder Accuracy', 'AutoEncoder Recall', 'AutoEncoder F1 Score',\n",
    "                                'AutoEncoder Fit Time', 'AutoEncoder Score Time',\n",
    "                                'LUNAR Precision', 'LUNAR AUC', 'LUNAR Accuracy', 'LUNAR Recall', 'LUNAR F1 Score',\n",
    "                                'LUNAR Fit Time', 'LUNAR Score Time'])\n",
    "algorithms = {\n",
    "    'iForest': IForest,\n",
    "    'AutoEncoder': AutoEncoder,\n",
    "    'LUNAR': LUNAR\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_semi_supervised_algorithm(algorithm, X, y):\n",
    "    if algorithm is AutoEncoder:\n",
    "        print('AutoEncoder')\n",
    "        clf = algorithm(\n",
    "            hidden_neurons=[16, 16, 4, 16, 16], epochs=5, contamination=np.mean(y))\n",
    "    else:\n",
    "        clf = algorithm(contamination=np.mean(y))\n",
    "\n",
    "    X_normal = X[y == 0]\n",
    "    X_anomaly = X[y == 1]\n",
    "\n",
    "    random_indices = np.random.choice(\n",
    "        len(X_normal), size=len(X_anomaly), replace=False)\n",
    "    array1 = X_normal[random_indices]\n",
    "    X_train = np.delete(X_normal, random_indices, axis=0)\n",
    "    X_test = np.concatenate((X_anomaly, array1), axis=0)\n",
    "    y_test = np.concatenate(\n",
    "        (np.ones(len(X_anomaly)), np.zeros(len(array1))), axis=0)\n",
    "\n",
    "    print(X_train.shape, X_test.shape, y_test.shape)\n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train)\n",
    "    end_time = time.time()\n",
    "    fit_time = round(end_time - start_time, ndigits=4)\n",
    "    test_scores = clf.decision_function(X_test)\n",
    "    start_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    score_time = round(end_time - start_time, ndigits=4)\n",
    "\n",
    "    precision = round(precision_score(y_test, y_pred), ndigits=4)\n",
    "    auc = round(roc_auc_score(y_test, test_scores), ndigits=4)\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), ndigits=4)\n",
    "    f1 = round(f1_score(y_test, y_pred), ndigits=4)\n",
    "    recall = round(recall_score(y_test, y_pred), ndigits=4)\n",
    "\n",
    "    return precision, auc, accuracy, f1, recall, fit_time, score_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iForest on fault...\n",
      "(595, 27) (1346, 27) (1346,)\n",
      "Running AutoEncoder on fault...\n",
      "AutoEncoder\n",
      "(595, 27) (1346, 27) (1346,)\n",
      "WARNING:tensorflow:From c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 27)                756       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 27)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                756       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 27)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                448       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 27)                459       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3111 (12.15 KB)\n",
      "Trainable params: 3111 (12.15 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "17/17 [==============================] - 4s 54ms/step - loss: 4.6366 - val_loss: 3.7834\n",
      "Epoch 2/5\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 3.4600 - val_loss: 3.2250\n",
      "Epoch 3/5\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.9490 - val_loss: 2.8995\n",
      "Epoch 4/5\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.6476 - val_loss: 2.6749\n",
      "Epoch 5/5\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 2.4296 - val_loss: 2.4911\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "43/43 [==============================] - 0s 1ms/step\n",
      "43/43 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on fault...\n",
      "(595, 27) (1346, 27) (1346,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iForest on glass...\n",
      "(196, 7) (18, 7) (18,)\n",
      "Running AutoEncoder on glass...\n",
      "AutoEncoder\n",
      "(196, 7) (18, 7) (18,)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                128       \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1051 (4.11 KB)\n",
      "Trainable params: 1051 (4.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 4s 84ms/step - loss: 2.1209 - val_loss: 1.7931\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9615 - val_loss: 1.7348\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9780 - val_loss: 1.6893\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.8548 - val_loss: 1.6501\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.8827 - val_loss: 1.6160\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Running LUNAR on glass...\n",
      "(196, 7) (18, 7) (18,)\n",
      "Running iForest on Hepatitis...\n",
      "(54, 19) (26, 19) (26,)\n",
      "Running AutoEncoder on Hepatitis...\n",
      "AutoEncoder\n",
      "(54, 19) (26, 19) (26,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 19)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 19)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 16)                320       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 19)                323       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2095 (8.18 KB)\n",
      "Trainable params: 2095 (8.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 4s 891ms/step - loss: 3.5479 - val_loss: 2.9467\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.4623 - val_loss: 2.9011\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.3075 - val_loss: 2.8571\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.3069 - val_loss: 2.8153\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.2396 - val_loss: 2.7769\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Running LUNAR on Hepatitis...\n",
      "(54, 19) (26, 19) (26,)\n",
      "Running iForest on InternetAds...\n",
      "(1230, 1555) (736, 1555) (736,)\n",
      "Running AutoEncoder on InternetAds...\n",
      "AutoEncoder\n",
      "(1230, 1555) (736, 1555) (736,)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 1555)              2419580   \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 1555)              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1555)              2419580   \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 1555)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 16)                24896     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1555)              26435     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4891183 (18.66 MB)\n",
      "Trainable params: 4891183 (18.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "35/35 [==============================] - 4s 43ms/step - loss: 188.8256 - val_loss: 252.0980\n",
      "Epoch 2/5\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 128.0788 - val_loss: 290.8050\n",
      "Epoch 3/5\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 64.1539 - val_loss: 362.0867\n",
      "Epoch 4/5\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 33.4542 - val_loss: 469.1967\n",
      "Epoch 5/5\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 19.0498 - val_loss: 587.1000\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "Running LUNAR on InternetAds...\n",
      "(1230, 1555) (736, 1555) (736,)\n",
      "Running iForest on Ionosphere...\n",
      "(99, 32) (252, 32) (252,)\n",
      "Running AutoEncoder on Ionosphere...\n",
      "AutoEncoder\n",
      "(99, 32) (252, 32) (252,)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3876 (15.14 KB)\n",
      "Trainable params: 3876 (15.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 4s 209ms/step - loss: 5.2629 - val_loss: 4.2166\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 4.8454 - val_loss: 3.9561\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 4.2747 - val_loss: 3.7441\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 4.0709 - val_loss: 3.5629\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.7940 - val_loss: 3.4086\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Running LUNAR on Ionosphere...\n",
      "(99, 32) (252, 32) (252,)\n",
      "Running iForest on landsat...\n",
      "(3769, 36) (2666, 36) (2666,)\n",
      "Running AutoEncoder on landsat...\n",
      "AutoEncoder\n",
      "(3769, 36) (2666, 36) (2666,)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 36)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 36)                0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 16)                592       \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 36)                612       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4560 (17.81 KB)\n",
      "Trainable params: 4560 (17.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "106/106 [==============================] - 3s 7ms/step - loss: 2.8571 - val_loss: 2.0407\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.8606 - val_loss: 1.4933\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 1.4722 - val_loss: 1.2837\n",
      "Epoch 4/5\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.3300 - val_loss: 1.1960\n",
      "Epoch 5/5\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 1.2596 - val_loss: 1.1456\n",
      "118/118 [==============================] - 0s 2ms/step\n",
      "84/84 [==============================] - 0s 1ms/step\n",
      "84/84 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on landsat...\n",
      "(3769, 36) (2666, 36) (2666,)\n",
      "Running iForest on letter...\n",
      "(1400, 32) (200, 32) (200,)\n",
      "Running AutoEncoder on letter...\n",
      "AutoEncoder\n",
      "(1400, 32) (200, 32) (200,)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3876 (15.14 KB)\n",
      "Trainable params: 3876 (15.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 4s 13ms/step - loss: 3.8957 - val_loss: 3.0641\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 2.7561 - val_loss: 2.4038\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.1938 - val_loss: 1.9752\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.8628 - val_loss: 1.7322\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.6607 - val_loss: 1.5788\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 502us/step\n",
      "Running LUNAR on letter...\n",
      "(1400, 32) (200, 32) (200,)\n",
      "Running iForest on magic...\n",
      "(5644, 10) (13376, 10) (13376,)\n",
      "Running AutoEncoder on magic...\n",
      "AutoEncoder\n",
      "(5644, 10) (13376, 10) (13376,)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 16)                176       \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1258 (4.91 KB)\n",
      "Trainable params: 1258 (4.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "159/159 [==============================] - 4s 5ms/step - loss: 1.9916 - val_loss: 1.5728\n",
      "Epoch 2/5\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.3840 - val_loss: 1.3189\n",
      "Epoch 3/5\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.2242 - val_loss: 1.2219\n",
      "Epoch 4/5\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.1548 - val_loss: 1.1722\n",
      "Epoch 5/5\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 1.1184 - val_loss: 1.1425\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "418/418 [==============================] - 1s 1ms/step\n",
      "418/418 [==============================] - 1s 1ms/step\n",
      "Running LUNAR on magic...\n",
      "(5644, 10) (13376, 10) (13376,)\n",
      "Running iForest on mammography...\n",
      "(10663, 6) (520, 6) (520,)\n",
      "Running AutoEncoder on mammography...\n",
      "AutoEncoder\n",
      "(10663, 6) (520, 6) (520,)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_64 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 16)                112       \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 990 (3.87 KB)\n",
      "Trainable params: 990 (3.87 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 5s 4ms/step - loss: 1.6276 - val_loss: 1.2966\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 1.1894 - val_loss: 1.1470\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.1009 - val_loss: 1.0975\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.0690 - val_loss: 1.0743\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.0524 - val_loss: 1.0605\n",
      "334/334 [==============================] - 1s 1ms/step\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on mammography...\n",
      "(10663, 6) (520, 6) (520,)\n",
      "Running iForest on mnist...\n",
      "(6203, 100) (1400, 100) (1400,)\n",
      "Running AutoEncoder on mnist...\n",
      "AutoEncoder\n",
      "(6203, 100) (1400, 100) (1400,)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 16)                1616      \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 100)               1700      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24208 (94.56 KB)\n",
      "Trainable params: 24208 (94.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 4s 5ms/step - loss: 5.7389 - val_loss: 1.7488\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 2.9083 - val_loss: 1.1081\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 2.3075 - val_loss: 0.9333\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 1.9284 - val_loss: 0.8486\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 1.6799 - val_loss: 0.7963\n",
      "194/194 [==============================] - 1s 1ms/step\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on mnist...\n",
      "(6203, 100) (1400, 100) (1400,)\n",
      "Running iForest on musk...\n",
      "(2868, 166) (194, 166) (194,)\n",
      "Running AutoEncoder on musk...\n",
      "AutoEncoder\n",
      "(2868, 166) (194, 166) (194,)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 166)               27722     \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 166)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 166)               27722     \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 166)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 16)                2672      \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 166)               2822      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61630 (240.74 KB)\n",
      "Trainable params: 61630 (240.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "81/81 [==============================] - 4s 9ms/step - loss: 7.9709 - val_loss: 4.9962\n",
      "Epoch 2/5\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 3.3039 - val_loss: 2.2342\n",
      "Epoch 3/5\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 2.0402 - val_loss: 1.7583\n",
      "Epoch 4/5\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 1.7095 - val_loss: 1.5564\n",
      "Epoch 5/5\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 1.5500 - val_loss: 1.4436\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on musk...\n",
      "(2868, 166) (194, 166) (194,)\n",
      "Running iForest on optdigits...\n",
      "(4916, 64) (300, 64) (300,)\n",
      "Running AutoEncoder on optdigits...\n",
      "AutoEncoder\n",
      "(4916, 64) (300, 64) (300,)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11140 (43.52 KB)\n",
      "Trainable params: 11140 (43.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "139/139 [==============================] - 4s 6ms/step - loss: 4.3399 - val_loss: 3.2054\n",
      "Epoch 2/5\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 2.0834 - val_loss: 2.3171\n",
      "Epoch 3/5\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 1.5767 - val_loss: 1.9225\n",
      "Epoch 4/5\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 1.3710 - val_loss: 1.7112\n",
      "Epoch 5/5\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 1.2631 - val_loss: 1.5746\n",
      "154/154 [==============================] - 0s 1ms/step\n",
      "10/10 [==============================] - 0s 893us/step\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on optdigits...\n",
      "(4916, 64) (300, 64) (300,)\n",
      "Running iForest on PageBlocks...\n",
      "(4373, 10) (1020, 10) (1020,)\n",
      "Running AutoEncoder on PageBlocks...\n",
      "AutoEncoder\n",
      "(4373, 10) (1020, 10) (1020,)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 16)                176       \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1258 (4.91 KB)\n",
      "Trainable params: 1258 (4.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "123/123 [==============================] - 4s 6ms/step - loss: 2.2938 - val_loss: 1.3663\n",
      "Epoch 2/5\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.6435 - val_loss: 1.0933\n",
      "Epoch 3/5\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.4218 - val_loss: 0.9798\n",
      "Epoch 4/5\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.3039 - val_loss: 0.9216\n",
      "Epoch 5/5\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 1.2549 - val_loss: 0.8862\n",
      "137/137 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Running LUNAR on PageBlocks...\n",
      "(4373, 10) (1020, 10) (1020,)\n",
      "Running iForest on pendigits...\n",
      "(6558, 16) (312, 16) (312,)\n",
      "Running AutoEncoder on pendigits...\n",
      "AutoEncoder\n",
      "(6558, 16) (312, 16) (312,)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1780 (6.95 KB)\n",
      "Trainable params: 1780 (6.95 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "185/185 [==============================] - 4s 5ms/step - loss: 1.9107 - val_loss: 1.4469\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 0s 3ms/step - loss: 1.3183 - val_loss: 1.2096\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 0s 3ms/step - loss: 1.1825 - val_loss: 1.1377\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 1.1336 - val_loss: 1.1041\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 1.1087 - val_loss: 1.0839\n",
      "205/205 [==============================] - 1s 1ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Running LUNAR on pendigits...\n",
      "(6558, 16) (312, 16) (312,)\n",
      "Running iForest on Pima...\n",
      "(232, 8) (536, 8) (536,)\n",
      "Running AutoEncoder on Pima...\n",
      "AutoEncoder\n",
      "(232, 8) (536, 8) (536,)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 16)                144       \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1116 (4.36 KB)\n",
      "Trainable params: 1116 (4.36 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 4s 82ms/step - loss: 2.7478 - val_loss: 2.7679\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.5925 - val_loss: 2.6043\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.5400 - val_loss: 2.4679\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.3503 - val_loss: 2.3544\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.1883 - val_loss: 2.2618\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "17/17 [==============================] - 0s 1000us/step\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on Pima...\n",
      "(232, 8) (536, 8) (536,)\n",
      "Running iForest on satimage-2...\n",
      "(5661, 36) (142, 36) (142,)\n",
      "Running AutoEncoder on satimage-2...\n",
      "AutoEncoder\n",
      "(5661, 36) (142, 36) (142,)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 36)                0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 36)                0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 16)                592       \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 36)                612       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4560 (17.81 KB)\n",
      "Trainable params: 4560 (17.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 4s 6ms/step - loss: 2.4485 - val_loss: 1.5531\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 1.4014 - val_loss: 1.2930\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.2502 - val_loss: 1.2058\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.1845 - val_loss: 1.1615\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 1.1480 - val_loss: 1.1342\n",
      "177/177 [==============================] - 1s 1ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "Running LUNAR on satimage-2...\n",
      "(5661, 36) (142, 36) (142,)\n",
      "Running iForest on SpamBase...\n",
      "(849, 57) (3358, 57) (3358,)\n",
      "Running AutoEncoder on SpamBase...\n",
      "AutoEncoder\n",
      "(849, 57) (3358, 57) (3358,)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_128 (Dense)           (None, 57)                3306      \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 57)                0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 57)                3306      \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 57)                0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 16)                928       \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 57)                969       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9201 (35.94 KB)\n",
      "Trainable params: 9201 (35.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 4s 23ms/step - loss: 7.0075 - val_loss: 5.9997\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 5.4633 - val_loss: 5.2404\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4.7439 - val_loss: 4.7492\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4.2254 - val_loss: 4.3284\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.7529 - val_loss: 3.8797\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 2ms/step\n",
      "Running LUNAR on SpamBase...\n",
      "(849, 57) (3358, 57) (3358,)\n",
      "Running iForest on speech...\n",
      "(3564, 400) (122, 400) (122,)\n",
      "Running AutoEncoder on speech...\n",
      "AutoEncoder\n",
      "(3564, 400) (122, 400) (122,)\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 400)               160400    \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 400)               0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 400)               160400    \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 400)               0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 16)                6416      \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 400)               6800      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 334708 (1.28 MB)\n",
      "Trainable params: 334708 (1.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "101/101 [==============================] - 4s 11ms/step - loss: 22.1301 - val_loss: 10.6033\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 6.7460 - val_loss: 4.9071\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 3.2892 - val_loss: 2.9840\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 2.2296 - val_loss: 2.2263\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 1.8404 - val_loss: 1.8770\n",
      "112/112 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Running LUNAR on speech...\n",
      "(3564, 400) (122, 400) (122,)\n",
      "Running iForest on Wilt...\n",
      "(4305, 5) (514, 5) (514,)\n",
      "Running AutoEncoder on Wilt...\n",
      "AutoEncoder\n",
      "(4305, 5) (514, 5) (514,)\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_144 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 16)                96        \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 933 (3.64 KB)\n",
      "Trainable params: 933 (3.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "122/122 [==============================] - 4s 6ms/step - loss: 1.3960 - val_loss: 1.7355\n",
      "Epoch 2/5\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 1.2027 - val_loss: 1.6167\n",
      "Epoch 3/5\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 1.1245 - val_loss: 1.5632\n",
      "Epoch 4/5\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 1.0858 - val_loss: 1.5318\n",
      "Epoch 5/5\n",
      "122/122 [==============================] - 0s 3ms/step - loss: 1.0599 - val_loss: 1.5118\n",
      "135/135 [==============================] - 0s 2ms/step\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "17/17 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on Wilt...\n",
      "(4305, 5) (514, 5) (514,)\n",
      "Running iForest on Cardiotocography...\n",
      "(1182, 21) (932, 21) (932,)\n",
      "Running AutoEncoder on Cardiotocography...\n",
      "AutoEncoder\n",
      "(1182, 21) (932, 21) (932,)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_152 (Dense)           (None, 21)                462       \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 21)                0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 21)                462       \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 21)                0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 21)                357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2325 (9.08 KB)\n",
      "Trainable params: 2325 (9.08 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "34/34 [==============================] - 3s 15ms/step - loss: 3.3447 - val_loss: 2.8104\n",
      "Epoch 2/5\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.6377 - val_loss: 2.4360\n",
      "Epoch 3/5\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.2679 - val_loss: 2.1737\n",
      "Epoch 4/5\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 2.0268 - val_loss: 1.9356\n",
      "Epoch 5/5\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.8166 - val_loss: 1.7522\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on Cardiotocography...\n",
      "(1182, 21) (932, 21) (932,)\n"
     ]
    }
   ],
   "source": [
    "for i, (dataset, dataset_name) in enumerate(zip(datasets, dataset_names)):\n",
    "    X = dataset['X']\n",
    "    y = dataset['y']\n",
    "    anomaly_ratio = np.mean(y)*100\n",
    "\n",
    "    for name, algorithm in algorithms.items():\n",
    "        print(f\"Running {name} on {dataset_name}...\")\n",
    "        precision, auc, accuracy, f1, recall, fit_time, score_time = evaluate_semi_supervised_algorithm(\n",
    "            algorithm, X, y)\n",
    "        results.loc[i, f'{name} Precision'] = precision\n",
    "        results.loc[i, f'{name} AUC'] = auc\n",
    "        results.loc[i, f'{name} Accuracy'] = accuracy\n",
    "        results.loc[i, f'{name} Recall'] = recall\n",
    "        results.loc[i, f'{name} F1 Score'] = f1\n",
    "        results.loc[i, f'{name} Fit Time'] = fit_time\n",
    "        results.loc[i, f'{name} Score Time'] = score_time\n",
    "\n",
    "    results.loc[i, 'Dataset'] = dataset_name\n",
    "    results.loc[i, '# Samples'] = X.shape[0]\n",
    "    results.loc[i, '# Features'] = X.shape[1]\n",
    "    results.loc[i, 'Anomaly Ratio'] = anomaly_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th># Samples</th>\n",
       "      <th># Features</th>\n",
       "      <th>Anomaly Ratio</th>\n",
       "      <th>iForest Precision</th>\n",
       "      <th>iForest AUC</th>\n",
       "      <th>iForest Accuracy</th>\n",
       "      <th>iForest Recall</th>\n",
       "      <th>iForest F1 Score</th>\n",
       "      <th>iForest Fit Time</th>\n",
       "      <th>...</th>\n",
       "      <th>AutoEncoder F1 Score</th>\n",
       "      <th>AutoEncoder Fit Time</th>\n",
       "      <th>AutoEncoder Score Time</th>\n",
       "      <th>LUNAR Precision</th>\n",
       "      <th>LUNAR AUC</th>\n",
       "      <th>LUNAR Accuracy</th>\n",
       "      <th>LUNAR Recall</th>\n",
       "      <th>LUNAR F1 Score</th>\n",
       "      <th>LUNAR Fit Time</th>\n",
       "      <th>LUNAR Score Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fault</td>\n",
       "      <td>1941</td>\n",
       "      <td>27</td>\n",
       "      <td>34.672849</td>\n",
       "      <td>0.6117</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>0.6048</td>\n",
       "      <td>0.5736</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>11.3658</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.7927</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>0.5513</td>\n",
       "      <td>0.6503</td>\n",
       "      <td>8.4339</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glass</td>\n",
       "      <td>214</td>\n",
       "      <td>7</td>\n",
       "      <td>4.205607</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.7284</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.7884</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>3.1747</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hepatitis</td>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7337</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6087</td>\n",
       "      <td>4.7968</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>2.3766</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InternetAds</td>\n",
       "      <td>1966</td>\n",
       "      <td>1555</td>\n",
       "      <td>18.71821</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.3728</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6949</td>\n",
       "      <td>9.6393</td>\n",
       "      <td>0.2244</td>\n",
       "      <td>0.8307</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>9.1712</td>\n",
       "      <td>0.0961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ionosphere</td>\n",
       "      <td>351</td>\n",
       "      <td>32</td>\n",
       "      <td>35.897436</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.8056</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>4.6974</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.9567</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>2.618</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>landsat</td>\n",
       "      <td>6435</td>\n",
       "      <td>36</td>\n",
       "      <td>20.714841</td>\n",
       "      <td>0.6445</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.3713</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.2399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344</td>\n",
       "      <td>5.4995</td>\n",
       "      <td>0.2609</td>\n",
       "      <td>0.8215</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.6999</td>\n",
       "      <td>0.5109</td>\n",
       "      <td>0.63</td>\n",
       "      <td>22.6455</td>\n",
       "      <td>0.0564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>letter</td>\n",
       "      <td>1600</td>\n",
       "      <td>32</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.5897</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.1996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>5.3937</td>\n",
       "      <td>0.1191</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>9.7978</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>magic</td>\n",
       "      <td>19020</td>\n",
       "      <td>10</td>\n",
       "      <td>35.162986</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.6617</td>\n",
       "      <td>0.7008</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.2561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>6.5919</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.8209</td>\n",
       "      <td>0.8473</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.7473</td>\n",
       "      <td>33.972</td>\n",
       "      <td>1.1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mammography</td>\n",
       "      <td>11183</td>\n",
       "      <td>6</td>\n",
       "      <td>2.324958</td>\n",
       "      <td>0.9391</td>\n",
       "      <td>0.8978</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.3203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601</td>\n",
       "      <td>8.9595</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>0.6981</td>\n",
       "      <td>0.4077</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>61.8515</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mnist</td>\n",
       "      <td>7603</td>\n",
       "      <td>100</td>\n",
       "      <td>9.206892</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.8487</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.3084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>7.1532</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.8479</td>\n",
       "      <td>0.7757</td>\n",
       "      <td>0.836</td>\n",
       "      <td>36.2766</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>musk</td>\n",
       "      <td>3062</td>\n",
       "      <td>166</td>\n",
       "      <td>3.167864</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>6.3506</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>17.676</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>optdigits</td>\n",
       "      <td>5216</td>\n",
       "      <td>64</td>\n",
       "      <td>2.875767</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.5167</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4659</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>28.889</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PageBlocks</td>\n",
       "      <td>5393</td>\n",
       "      <td>10</td>\n",
       "      <td>9.456703</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.8147</td>\n",
       "      <td>0.7294</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>6.6463</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.6658</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.7441</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.793</td>\n",
       "      <td>26.241</td>\n",
       "      <td>0.0646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pendigits</td>\n",
       "      <td>6870</td>\n",
       "      <td>16</td>\n",
       "      <td>2.270742</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.7981</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>6.8795</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>38.577</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pima</td>\n",
       "      <td>768</td>\n",
       "      <td>8</td>\n",
       "      <td>34.895833</td>\n",
       "      <td>0.6215</td>\n",
       "      <td>0.7187</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.7537</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>5.178</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.5821</td>\n",
       "      <td>0.646</td>\n",
       "      <td>3.2806</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>satimage-2</td>\n",
       "      <td>5803</td>\n",
       "      <td>36</td>\n",
       "      <td>1.223505</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>0.9507</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9323</td>\n",
       "      <td>6.6192</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>33.3944</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SpamBase</td>\n",
       "      <td>4207</td>\n",
       "      <td>57</td>\n",
       "      <td>39.909674</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.8354</td>\n",
       "      <td>0.7219</td>\n",
       "      <td>0.8618</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7379</td>\n",
       "      <td>5.1136</td>\n",
       "      <td>0.3122</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.8118</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7.1135</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>speech</td>\n",
       "      <td>3686</td>\n",
       "      <td>400</td>\n",
       "      <td>1.65491</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>7.6515</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.5942</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.2951</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>22.0068</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wilt</td>\n",
       "      <td>4819</td>\n",
       "      <td>5</td>\n",
       "      <td>5.333057</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.5656</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>6.0372</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>25.374</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cardiotocography</td>\n",
       "      <td>2114</td>\n",
       "      <td>21</td>\n",
       "      <td>22.043519</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.7996</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.7189</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7118</td>\n",
       "      <td>4.7888</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>0.7406</td>\n",
       "      <td>10.0378</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dataset # Samples # Features Anomaly Ratio iForest Precision  \\\n",
       "0              fault      1941         27     34.672849            0.6117   \n",
       "1              glass       214          7      4.205607            0.3333   \n",
       "2          Hepatitis        80         19         16.25            0.6667   \n",
       "3        InternetAds      1966       1555      18.71821            0.2048   \n",
       "4         Ionosphere       351         32     35.897436            0.7391   \n",
       "5            landsat      6435         36     20.714841            0.6445   \n",
       "6             letter      1600         32          6.25            0.5263   \n",
       "7              magic     19020         10     35.162986              0.65   \n",
       "8        mammography     11183          6      2.324958            0.9391   \n",
       "9              mnist      7603        100      9.206892            0.8488   \n",
       "10              musk      3062        166      3.167864            0.9898   \n",
       "11         optdigits      5216         64      2.875767            0.6923   \n",
       "12        PageBlocks      5393         10      9.456703            0.8794   \n",
       "13         pendigits      6870         16      2.270742            0.9794   \n",
       "14              Pima       768          8     34.895833            0.6215   \n",
       "15        satimage-2      5803         36      1.223505            0.9848   \n",
       "16          SpamBase      4207         57     39.909674            0.6733   \n",
       "17            speech      3686        400       1.65491               1.0   \n",
       "18              Wilt      4819          5      5.333057            0.1875   \n",
       "19  Cardiotocography      2114         21     22.043519            0.7251   \n",
       "\n",
       "   iForest AUC iForest Accuracy iForest Recall iForest F1 Score  \\\n",
       "0       0.6554           0.6048         0.5736            0.592   \n",
       "1       0.7284           0.4444         0.1111           0.1667   \n",
       "2       0.7337           0.6538         0.6154             0.64   \n",
       "3       0.3728           0.4334         0.0462           0.0754   \n",
       "4       0.9235           0.8056         0.9444           0.8293   \n",
       "5       0.6172           0.5833         0.3713           0.4712   \n",
       "6       0.5897            0.505            0.1           0.1681   \n",
       "7        0.748           0.6617         0.7008           0.6744   \n",
       "8       0.8978           0.6942         0.4154            0.576   \n",
       "9       0.8487           0.7043         0.4971            0.627   \n",
       "10      0.9986           0.9948            1.0           0.9949   \n",
       "11      0.7576           0.5167           0.06           0.1104   \n",
       "12      0.9237           0.8147         0.7294           0.7974   \n",
       "13      0.9745           0.7981          0.609            0.751   \n",
       "14      0.7187           0.6474         0.7537           0.6813   \n",
       "15      0.9962           0.9507         0.9155           0.9489   \n",
       "16      0.8354           0.7219         0.8618            0.756   \n",
       "17      0.5179           0.5082         0.0164           0.0323   \n",
       "18      0.5656           0.4805         0.0117            0.022   \n",
       "19      0.7996           0.7232         0.7189            0.722   \n",
       "\n",
       "   iForest Fit Time  ... AutoEncoder F1 Score AutoEncoder Fit Time  \\\n",
       "0            0.1761  ...               0.5058              11.3658   \n",
       "1            0.1755  ...                  0.2               4.7884   \n",
       "2             0.168  ...               0.6087               4.7968   \n",
       "3            0.2195  ...               0.6949               9.6393   \n",
       "4            0.1681  ...               0.7986               4.6974   \n",
       "5            0.2399  ...                0.344               5.4995   \n",
       "6            0.1996  ...               0.1239               5.3937   \n",
       "7            0.2561  ...               0.6304               6.5919   \n",
       "8            0.3203  ...                0.601               8.9595   \n",
       "9            0.3084  ...               0.8087               7.1532   \n",
       "10           0.2241  ...               0.9798               6.3506   \n",
       "11           0.2559  ...                  0.0               6.4659   \n",
       "12            0.237  ...               0.8233               6.6463   \n",
       "13            0.296  ...               0.5636               6.8795   \n",
       "14           0.1763  ...               0.5187                5.178   \n",
       "15           0.2556  ...               0.9323               6.6192   \n",
       "16           0.1681  ...               0.7379               5.1136   \n",
       "17           0.2427  ...               0.0635               7.6515   \n",
       "18           0.2239  ...               0.0147               6.0372   \n",
       "19            0.892  ...               0.7118               4.7888   \n",
       "\n",
       "   AutoEncoder Score Time LUNAR Precision LUNAR AUC LUNAR Accuracy  \\\n",
       "0                  0.1681          0.7927     0.813         0.7036   \n",
       "1                  0.0961          0.6667    0.6543         0.7222   \n",
       "2                  0.0891          0.8889    0.8402         0.7692   \n",
       "3                  0.2244          0.8307    0.8628         0.7867   \n",
       "4                   0.129          0.8214    0.9567         0.8571   \n",
       "5                  0.2609          0.8215    0.7882         0.6999   \n",
       "6                  0.1191          0.9123    0.9298          0.735   \n",
       "7                  0.8132          0.8209    0.8473         0.7681   \n",
       "8                  0.1271          0.9725    0.8906         0.6981   \n",
       "9                  0.1759          0.9065     0.932         0.8479   \n",
       "10                 0.1041          0.9798       1.0         0.9897   \n",
       "11                 0.1234           0.974    0.9994         0.9867   \n",
       "12                 0.1521          0.6658    0.9382         0.7441   \n",
       "13                 0.1051          0.9935    0.9998         0.9904   \n",
       "14                 0.1282          0.7256     0.738          0.681   \n",
       "15                 0.1192          0.9855    0.9976         0.9718   \n",
       "16                 0.3122          0.7506    0.8447          0.771   \n",
       "17                 0.1121            0.72    0.5942         0.5902   \n",
       "18                 0.1524          0.1333    0.5857         0.4572   \n",
       "19                 0.1481           0.635    0.8122         0.6888   \n",
       "\n",
       "   LUNAR Recall LUNAR F1 Score LUNAR Fit Time LUNAR Score Time  \n",
       "0        0.5513         0.6503         8.4339            0.016  \n",
       "1        0.8889         0.7619         3.1747            0.002  \n",
       "2        0.6154         0.7273         2.3766            0.008  \n",
       "3        0.7201         0.7715         9.1712           0.0961  \n",
       "4        0.9127         0.8647          2.618              0.0  \n",
       "5        0.5109           0.63        22.6455           0.0564  \n",
       "6          0.52         0.6624         9.7978            0.008  \n",
       "7        0.6859         0.7473         33.972           1.1786  \n",
       "8        0.4077         0.5745        61.8515            0.029  \n",
       "9        0.7757          0.836        36.2766            0.048  \n",
       "10          1.0         0.9898         17.676            0.008  \n",
       "11          1.0         0.9868         28.889           0.0081  \n",
       "12       0.9804          0.793         26.241           0.0646  \n",
       "13       0.9872         0.9904         38.577            0.008  \n",
       "14       0.5821          0.646         3.2806            0.008  \n",
       "15       0.9577         0.9714        33.3944            0.008  \n",
       "16       0.8118           0.78         7.1135            0.027  \n",
       "17       0.2951         0.4186        22.0068            0.016  \n",
       "18       0.0156         0.0279         25.374            0.008  \n",
       "19       0.8884         0.7406        10.0378            0.008  \n",
       "\n",
       "[20 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv('results.csv', index=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def evaluate_semi_supervised_algorithm_stratified(algorithm, X, y, test_size=0.3):\n",
    "    if algorithm is AutoEncoder:\n",
    "        clf = algorithm(\n",
    "            hidden_neurons=[16, 16, 4, 16, 16], epochs=25, contamination=np.mean(y))\n",
    "    else:\n",
    "        clf = algorithm(contamination=np.mean(y))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y)\n",
    "    X_train_normal = X_train[y_train == 0]\n",
    "    print(y.mean(), y_train.mean(), y_test.mean())\n",
    "\n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train_normal)\n",
    "    end_time = time.time()\n",
    "    fit_time = round(end_time - start_time, ndigits=4)\n",
    "    test_scores = clf.decision_function(X_test)\n",
    "    start_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    score_time = round(end_time - start_time, ndigits=4)\n",
    "\n",
    "    precision = round(precision_score(y_test, y_pred), ndigits=4)\n",
    "    auc = round(roc_auc_score(y_test, test_scores), ndigits=4)\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), ndigits=4)\n",
    "    f1 = round(f1_score(y_test, y_pred), ndigits=4)\n",
    "    recall = round(recall_score(y_test, y_pred), ndigits=4)\n",
    "\n",
    "    return precision, auc, accuracy, f1, recall, fit_time, score_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iForest on fault...\n",
      "0.3467284904688305 0.34683357879234167 0.346483704974271\n",
      "Running AutoEncoder on fault...\n",
      "0.3467284904688305 0.34683357879234167 0.346483704974271\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 27)                756       \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 27)                0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 27)                756       \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 27)                0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 16)                448       \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 27)                459       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3111 (12.15 KB)\n",
      "Trainable params: 3111 (12.15 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 3s 12ms/step - loss: 4.5659 - val_loss: 3.0260\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.3637 - val_loss: 2.5832\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.9133 - val_loss: 2.3096\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.6525 - val_loss: 2.0835\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.3403 - val_loss: 1.8821\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.1669 - val_loss: 1.7160\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.9851 - val_loss: 1.5941\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.8733 - val_loss: 1.5019\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.7461 - val_loss: 1.4282\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.6700 - val_loss: 1.3686\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.5928 - val_loss: 1.3178\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.5295 - val_loss: 1.2771\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.5004 - val_loss: 1.2425\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4424 - val_loss: 1.2141\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4067 - val_loss: 1.1898\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.3877 - val_loss: 1.1687\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3523 - val_loss: 1.1509\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3332 - val_loss: 1.1353\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.3098 - val_loss: 1.1214\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2965 - val_loss: 1.1095\n",
      "Epoch 21/25\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2797 - val_loss: 1.0988\n",
      "Epoch 22/25\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2658 - val_loss: 1.0887\n",
      "Epoch 23/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2576 - val_loss: 1.0804\n",
      "Epoch 24/25\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2412 - val_loss: 1.0728\n",
      "Epoch 25/25\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2367 - val_loss: 1.0659\n",
      "28/28 [==============================] - 0s 784us/step\n",
      "19/19 [==============================] - 0s 826us/step\n",
      "19/19 [==============================] - 0s 671us/step\n",
      "Running LUNAR on fault...\n",
      "0.3467284904688305 0.34683357879234167 0.346483704974271\n",
      "Running iForest on glass...\n",
      "0.04205607476635514 0.040268456375838924 0.046153846153846156\n",
      "Running AutoEncoder on glass...\n",
      "0.04205607476635514 0.040268456375838924 0.046153846153846156\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_168 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 7)                 56        \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 16)                128       \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1051 (4.11 KB)\n",
      "Trainable params: 1051 (4.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "4/4 [==============================] - 2s 76ms/step - loss: 2.2103 - val_loss: 1.7331\n",
      "Epoch 2/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.1646 - val_loss: 1.7074\n",
      "Epoch 3/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.1404 - val_loss: 1.6841\n",
      "Epoch 4/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.0869 - val_loss: 1.6634\n",
      "Epoch 5/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9851 - val_loss: 1.6453\n",
      "Epoch 6/25\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.9656 - val_loss: 1.6283\n",
      "Epoch 7/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8845 - val_loss: 1.6128\n",
      "Epoch 8/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8635 - val_loss: 1.5982\n",
      "Epoch 9/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8663 - val_loss: 1.5846\n",
      "Epoch 10/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8596 - val_loss: 1.5709\n",
      "Epoch 11/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8397 - val_loss: 1.5577\n",
      "Epoch 12/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8142 - val_loss: 1.5446\n",
      "Epoch 13/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7463 - val_loss: 1.5322\n",
      "Epoch 14/25\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.7690 - val_loss: 1.5200\n",
      "Epoch 15/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7824 - val_loss: 1.5083\n",
      "Epoch 16/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7053 - val_loss: 1.4968\n",
      "Epoch 17/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6885 - val_loss: 1.4855\n",
      "Epoch 18/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7061 - val_loss: 1.4746\n",
      "Epoch 19/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6559 - val_loss: 1.4637\n",
      "Epoch 20/25\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.6597 - val_loss: 1.4529\n",
      "Epoch 21/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6404 - val_loss: 1.4424\n",
      "Epoch 22/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6160 - val_loss: 1.4320\n",
      "Epoch 23/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6145 - val_loss: 1.4219\n",
      "Epoch 24/25\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.5869 - val_loss: 1.4116\n",
      "Epoch 25/25\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.5687 - val_loss: 1.4016\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "Running LUNAR on glass...\n",
      "0.04205607476635514 0.040268456375838924 0.046153846153846156\n",
      "Running iForest on Hepatitis...\n",
      "0.1625 0.16071428571428573 0.16666666666666666\n",
      "Running AutoEncoder on Hepatitis...\n",
      "0.1625 0.16071428571428573 0.16666666666666666\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_176 (Dense)           (None, 19)                380       \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 19)                0         \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 19)                380       \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 19)                0         \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 16)                320       \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 19)                323       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2095 (8.18 KB)\n",
      "Trainable params: 2095 (8.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/25\n",
      "2/2 [==============================] - 2s 252ms/step - loss: 3.9176 - val_loss: 2.3629\n",
      "Epoch 2/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.9947 - val_loss: 2.3280\n",
      "Epoch 3/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.6589 - val_loss: 2.2967\n",
      "Epoch 4/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.5921 - val_loss: 2.2691\n",
      "Epoch 5/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.5582 - val_loss: 2.2438\n",
      "Epoch 6/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.4937 - val_loss: 2.2209\n",
      "Epoch 7/25\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.4408 - val_loss: 2.1998\n",
      "Epoch 8/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.3575 - val_loss: 2.1796\n",
      "Epoch 9/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.3038 - val_loss: 2.1603\n",
      "Epoch 10/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.1843 - val_loss: 2.1423\n",
      "Epoch 11/25\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.1160 - val_loss: 2.1255\n",
      "Epoch 12/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.0162 - val_loss: 2.1096\n",
      "Epoch 13/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.0043 - val_loss: 2.0940\n",
      "Epoch 14/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.0089 - val_loss: 2.0791\n",
      "Epoch 15/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.9117 - val_loss: 2.0646\n",
      "Epoch 16/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.9016 - val_loss: 2.0505\n",
      "Epoch 17/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.8580 - val_loss: 2.0369\n",
      "Epoch 18/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.8711 - val_loss: 2.0233\n",
      "Epoch 19/25\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.7932 - val_loss: 2.0105\n",
      "Epoch 20/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.7765 - val_loss: 1.9983\n",
      "Epoch 21/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.7499 - val_loss: 1.9861\n",
      "Epoch 22/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.7328 - val_loss: 1.9740\n",
      "Epoch 23/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.6518 - val_loss: 1.9620\n",
      "Epoch 24/25\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.6934 - val_loss: 1.9505\n",
      "Epoch 25/25\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.6498 - val_loss: 1.9394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Running LUNAR on Hepatitis...\n",
      "0.1625 0.16071428571428573 0.16666666666666666\n",
      "Running iForest on InternetAds...\n",
      "0.1871820956256358 0.1875 0.1864406779661017\n",
      "Running AutoEncoder on InternetAds...\n",
      "0.1871820956256358 0.1875 0.1864406779661017\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_184 (Dense)           (None, 1555)              2419580   \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 1555)              0         \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 1555)              2419580   \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 1555)              0         \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 16)                24896     \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 1555)              26435     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4891183 (18.66 MB)\n",
      "Trainable params: 4891183 (18.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "32/32 [==============================] - 3s 33ms/step - loss: 202.2045 - val_loss: 407.1028\n",
      "Epoch 2/25\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 114.8284 - val_loss: 1012.1797\n",
      "Epoch 3/25\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 64.4860 - val_loss: 1666.6500\n",
      "Epoch 4/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 32.1667 - val_loss: 2460.8086\n",
      "Epoch 5/25\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 17.2572 - val_loss: 3117.8960\n",
      "Epoch 6/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 10.9564 - val_loss: 3911.5762\n",
      "Epoch 7/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.7815 - val_loss: 4644.1963\n",
      "Epoch 8/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 5.6736 - val_loss: 5275.0518\n",
      "Epoch 9/25\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 4.3671 - val_loss: 5852.8442\n",
      "Epoch 10/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 3.6217 - val_loss: 6300.9360\n",
      "Epoch 11/25\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 3.0911 - val_loss: 6683.2153\n",
      "Epoch 12/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 2.7342 - val_loss: 7002.1919\n",
      "Epoch 13/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 2.5139 - val_loss: 7275.0391\n",
      "Epoch 14/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 2.3389 - val_loss: 7499.5586\n",
      "Epoch 15/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 2.2541 - val_loss: 7681.1104\n",
      "Epoch 16/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 2.1150 - val_loss: 7841.1328\n",
      "Epoch 17/25\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 2.0384 - val_loss: 7967.9165\n",
      "Epoch 18/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 1.9889 - val_loss: 8072.1143\n",
      "Epoch 19/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 1.9516 - val_loss: 8152.4360\n",
      "Epoch 20/25\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 1.8902 - val_loss: 8227.1182\n",
      "Epoch 21/25\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 1.8376 - val_loss: 8286.5703\n",
      "Epoch 22/25\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 1.7713 - val_loss: 8337.8154\n",
      "Epoch 23/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 1.7614 - val_loss: 8379.6270\n",
      "Epoch 24/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 1.7407 - val_loss: 8418.1299\n",
      "Epoch 25/25\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 1.7056 - val_loss: 8461.5312\n",
      "35/35 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Running LUNAR on InternetAds...\n",
      "0.1871820956256358 0.1875 0.1864406779661017\n",
      "Running iForest on Ionosphere...\n",
      "0.358974358974359 0.35918367346938773 0.3584905660377358\n",
      "Running AutoEncoder on Ionosphere...\n",
      "0.358974358974359 0.35918367346938773 0.3584905660377358\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_192 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 32)                544       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3876 (15.14 KB)\n",
      "Trainable params: 3876 (15.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "5/5 [==============================] - 2s 60ms/step - loss: 4.3025 - val_loss: 4.6195\n",
      "Epoch 2/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.7399 - val_loss: 4.1912\n",
      "Epoch 3/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.4090 - val_loss: 3.8854\n",
      "Epoch 4/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.1158 - val_loss: 3.6539\n",
      "Epoch 5/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9359 - val_loss: 3.4726\n",
      "Epoch 6/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7768 - val_loss: 3.3272\n",
      "Epoch 7/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6414 - val_loss: 3.2171\n",
      "Epoch 8/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.5542 - val_loss: 3.1278\n",
      "Epoch 9/25\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4634 - val_loss: 3.0551\n",
      "Epoch 10/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3899 - val_loss: 2.9925\n",
      "Epoch 11/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.3322 - val_loss: 2.9380\n",
      "Epoch 12/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.2740 - val_loss: 2.8898\n",
      "Epoch 13/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.2314 - val_loss: 2.8475\n",
      "Epoch 14/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.1899 - val_loss: 2.8073\n",
      "Epoch 15/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1496 - val_loss: 2.7713\n",
      "Epoch 16/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.1139 - val_loss: 2.7371\n",
      "Epoch 17/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0778 - val_loss: 2.7055\n",
      "Epoch 18/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0438 - val_loss: 2.6750\n",
      "Epoch 19/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0127 - val_loss: 2.6456\n",
      "Epoch 20/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9773 - val_loss: 2.6154\n",
      "Epoch 21/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9445 - val_loss: 2.5841\n",
      "Epoch 22/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9194 - val_loss: 2.5529\n",
      "Epoch 23/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8852 - val_loss: 2.5221\n",
      "Epoch 24/25\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8500 - val_loss: 2.4912\n",
      "Epoch 25/25\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.8245 - val_loss: 2.4594\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on Ionosphere...\n",
      "0.358974358974359 0.35918367346938773 0.3584905660377358\n",
      "Running iForest on landsat...\n",
      "0.20714840714840715 0.20714920071047957 0.20714655618850336\n",
      "Running AutoEncoder on landsat...\n",
      "0.20714840714840715 0.20714920071047957 0.20714655618850336\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_200 (Dense)           (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 36)                0         \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 36)                0         \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 16)                592       \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 36)                612       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4560 (17.81 KB)\n",
      "Trainable params: 4560 (17.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "101/101 [==============================] - 3s 4ms/step - loss: 3.2044 - val_loss: 2.1212\n",
      "Epoch 2/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.7362 - val_loss: 1.4767\n",
      "Epoch 3/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3982 - val_loss: 1.3157\n",
      "Epoch 4/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2862 - val_loss: 1.2419\n",
      "Epoch 5/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2289 - val_loss: 1.1974\n",
      "Epoch 6/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1903 - val_loss: 1.1673\n",
      "Epoch 7/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1650 - val_loss: 1.1455\n",
      "Epoch 8/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1464 - val_loss: 1.1289\n",
      "Epoch 9/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1304 - val_loss: 1.1160\n",
      "Epoch 10/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1190 - val_loss: 1.1055\n",
      "Epoch 11/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1084 - val_loss: 1.0968\n",
      "Epoch 12/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1008 - val_loss: 1.0895\n",
      "Epoch 13/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0944 - val_loss: 1.0831\n",
      "Epoch 14/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0879 - val_loss: 1.0775\n",
      "Epoch 15/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0831 - val_loss: 1.0726\n",
      "Epoch 16/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0784 - val_loss: 1.0682\n",
      "Epoch 17/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0739 - val_loss: 1.0642\n",
      "Epoch 18/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0694 - val_loss: 1.0606\n",
      "Epoch 19/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0667 - val_loss: 1.0573\n",
      "Epoch 20/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0639 - val_loss: 1.0543\n",
      "Epoch 21/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0602 - val_loss: 1.0515\n",
      "Epoch 22/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0571 - val_loss: 1.0489\n",
      "Epoch 23/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0548 - val_loss: 1.0466\n",
      "Epoch 24/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0530 - val_loss: 1.0443\n",
      "Epoch 25/25\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0497 - val_loss: 1.0422\n",
      "112/112 [==============================] - 0s 771us/step\n",
      "61/61 [==============================] - 0s 762us/step\n",
      "61/61 [==============================] - 0s 763us/step\n",
      "Running LUNAR on landsat...\n",
      "0.20714840714840715 0.20714920071047957 0.20714655618850336\n",
      "Running iForest on letter...\n",
      "0.0625 0.0625 0.0625\n",
      "Running AutoEncoder on letter...\n",
      "0.0625 0.0625 0.0625\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_208 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 32)                544       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3876 (15.14 KB)\n",
      "Trainable params: 3876 (15.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "30/30 [==============================] - 2s 9ms/step - loss: 4.3037 - val_loss: 3.1772\n",
      "Epoch 2/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 3.1460 - val_loss: 2.6505\n",
      "Epoch 3/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.6425 - val_loss: 2.3062\n",
      "Epoch 4/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.2913 - val_loss: 2.0133\n",
      "Epoch 5/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 2.0125 - val_loss: 1.7929\n",
      "Epoch 6/25\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8262 - val_loss: 1.6463\n",
      "Epoch 7/25\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.6895 - val_loss: 1.5419\n",
      "Epoch 8/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5903 - val_loss: 1.4637\n",
      "Epoch 9/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.5231 - val_loss: 1.4035\n",
      "Epoch 10/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4612 - val_loss: 1.3545\n",
      "Epoch 11/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.4112 - val_loss: 1.3141\n",
      "Epoch 12/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.3728 - val_loss: 1.2790\n",
      "Epoch 13/25\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.3379 - val_loss: 1.2489\n",
      "Epoch 14/25\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.3062 - val_loss: 1.2238\n",
      "Epoch 15/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2873 - val_loss: 1.2026\n",
      "Epoch 16/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2621 - val_loss: 1.1845\n",
      "Epoch 17/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2477 - val_loss: 1.1691\n",
      "Epoch 18/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2302 - val_loss: 1.1556\n",
      "Epoch 19/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2170 - val_loss: 1.1440\n",
      "Epoch 20/25\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.2069 - val_loss: 1.1338\n",
      "Epoch 21/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1964 - val_loss: 1.1247\n",
      "Epoch 22/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1861 - val_loss: 1.1167\n",
      "Epoch 23/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1840 - val_loss: 1.1094\n",
      "Epoch 24/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1740 - val_loss: 1.1030\n",
      "Epoch 25/25\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1649 - val_loss: 1.0973\n",
      "33/33 [==============================] - 0s 766us/step\n",
      "15/15 [==============================] - 0s 832us/step\n",
      "15/15 [==============================] - 0s 936us/step\n",
      "Running LUNAR on letter...\n",
      "0.0625 0.0625 0.0625\n",
      "Running iForest on magic...\n",
      "0.3516298633017876 0.3516599068649542 0.3515597616543989\n",
      "Running AutoEncoder on magic...\n",
      "0.3516298633017876 0.3516599068649542 0.3515597616543989\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_216 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dropout_190 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 16)                176       \n",
      "                                                                 \n",
      " dropout_191 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_194 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_195 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1258 (4.91 KB)\n",
      "Trainable params: 1258 (4.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "243/243 [==============================] - 3s 2ms/step - loss: 1.7437 - val_loss: 1.3058\n",
      "Epoch 2/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.2233 - val_loss: 1.1480\n",
      "Epoch 3/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.1290 - val_loss: 1.0963\n",
      "Epoch 4/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0930 - val_loss: 1.0713\n",
      "Epoch 5/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0727 - val_loss: 1.0562\n",
      "Epoch 6/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0603 - val_loss: 1.0459\n",
      "Epoch 7/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0505 - val_loss: 1.0383\n",
      "Epoch 8/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0444 - val_loss: 1.0323\n",
      "Epoch 9/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0388 - val_loss: 1.0275\n",
      "Epoch 10/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0344 - val_loss: 1.0234\n",
      "Epoch 11/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0308 - val_loss: 1.0201\n",
      "Epoch 12/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0276 - val_loss: 1.0171\n",
      "Epoch 13/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0248 - val_loss: 1.0146\n",
      "Epoch 14/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0223 - val_loss: 1.0124\n",
      "Epoch 15/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0203 - val_loss: 1.0104\n",
      "Epoch 16/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0185 - val_loss: 1.0086\n",
      "Epoch 17/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0169 - val_loss: 1.0070\n",
      "Epoch 18/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0152 - val_loss: 1.0056\n",
      "Epoch 19/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0141 - val_loss: 1.0045\n",
      "Epoch 20/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0130 - val_loss: 1.0032\n",
      "Epoch 21/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0117 - val_loss: 1.0021\n",
      "Epoch 22/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0108 - val_loss: 1.0013\n",
      "Epoch 23/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0101 - val_loss: 1.0003\n",
      "Epoch 24/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0092 - val_loss: 0.9997\n",
      "Epoch 25/25\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 1.0085 - val_loss: 0.9988\n",
      "270/270 [==============================] - 0s 719us/step\n",
      "179/179 [==============================] - 0s 719us/step\n",
      "179/179 [==============================] - 0s 720us/step\n",
      "Running LUNAR on magic...\n",
      "0.3516298633017876 0.3516599068649542 0.3515597616543989\n",
      "Running iForest on mammography...\n",
      "0.023249575248144506 0.023249872253449155 0.02324888226527571\n",
      "Running AutoEncoder on mammography...\n",
      "0.023249575248144506 0.023249872253449155 0.02324888226527571\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_224 (Dense)           (None, 6)                 42        \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 6)                 42        \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 16)                112       \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_200 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_201 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_202 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 990 (3.87 KB)\n",
      "Trainable params: 990 (3.87 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "216/216 [==============================] - 2s 2ms/step - loss: 1.4487 - val_loss: 1.1599\n",
      "Epoch 2/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1.1904 - val_loss: 1.0413\n",
      "Epoch 3/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1.1112 - val_loss: 0.9763\n",
      "Epoch 4/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1.0643 - val_loss: 0.9384\n",
      "Epoch 5/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1.0331 - val_loss: 0.9153\n",
      "Epoch 6/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 1.0144 - val_loss: 0.8995\n",
      "Epoch 7/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.8852\n",
      "Epoch 8/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9870 - val_loss: 0.8757\n",
      "Epoch 9/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9754 - val_loss: 0.8691\n",
      "Epoch 10/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 0.8637\n",
      "Epoch 11/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.8573\n",
      "Epoch 12/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.8515\n",
      "Epoch 13/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 0.8512\n",
      "Epoch 14/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.8466\n",
      "Epoch 15/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9429 - val_loss: 0.8415\n",
      "Epoch 16/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9396 - val_loss: 0.8403\n",
      "Epoch 17/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9359 - val_loss: 0.8368\n",
      "Epoch 18/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.8363\n",
      "Epoch 19/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.8350\n",
      "Epoch 20/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.8302\n",
      "Epoch 21/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.8286\n",
      "Epoch 22/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.8266\n",
      "Epoch 23/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.8269\n",
      "Epoch 24/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9237 - val_loss: 0.8250\n",
      "Epoch 25/25\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.8222\n",
      "239/239 [==============================] - 0s 743us/step\n",
      "105/105 [==============================] - 0s 790us/step\n",
      "105/105 [==============================] - 0s 749us/step\n",
      "Running LUNAR on mammography...\n",
      "0.023249575248144506 0.023249872253449155 0.02324888226527571\n",
      "Running iForest on mnist...\n",
      "0.09206892016309351 0.0920706501315295 0.0920648838228847\n",
      "Running AutoEncoder on mnist...\n",
      "0.09206892016309351 0.0920706501315295 0.0920648838228847\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_232 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_203 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 16)                1616      \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_206 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_207 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_208 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_209 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 100)               1700      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24208 (94.56 KB)\n",
      "Trainable params: 24208 (94.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "136/136 [==============================] - 3s 6ms/step - loss: 5.0650 - val_loss: 2.6598\n",
      "Epoch 2/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.3629 - val_loss: 1.6754\n",
      "Epoch 3/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.7470 - val_loss: 1.3124\n",
      "Epoch 4/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.4605 - val_loss: 1.1281\n",
      "Epoch 5/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.2943 - val_loss: 1.0242\n",
      "Epoch 6/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.1822 - val_loss: 0.9434\n",
      "Epoch 7/25\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0999 - val_loss: 0.8923\n",
      "Epoch 8/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.0338 - val_loss: 0.8580\n",
      "Epoch 9/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9810 - val_loss: 0.8295\n",
      "Epoch 10/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.8099\n",
      "Epoch 11/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.9036 - val_loss: 0.7946\n",
      "Epoch 12/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8754 - val_loss: 0.7824\n",
      "Epoch 13/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8511 - val_loss: 0.7720\n",
      "Epoch 14/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8311 - val_loss: 0.7641\n",
      "Epoch 15/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.8139 - val_loss: 0.7568\n",
      "Epoch 16/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7985 - val_loss: 0.7501\n",
      "Epoch 17/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7862 - val_loss: 0.7445\n",
      "Epoch 18/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7764 - val_loss: 0.7402\n",
      "Epoch 19/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7662 - val_loss: 0.7358\n",
      "Epoch 20/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7588 - val_loss: 0.7314\n",
      "Epoch 21/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7525 - val_loss: 0.7281\n",
      "Epoch 22/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7467 - val_loss: 0.7247\n",
      "Epoch 23/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7419 - val_loss: 0.7216\n",
      "Epoch 24/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7366 - val_loss: 0.7186\n",
      "Epoch 25/25\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.7333 - val_loss: 0.7161\n",
      "151/151 [==============================] - 0s 1ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on mnist...\n",
      "0.09206892016309351 0.0920706501315295 0.0920648838228847\n",
      "Running iForest on musk...\n",
      "0.03167864141084259 0.03173121791880541 0.031556039173014146\n",
      "Running AutoEncoder on musk...\n",
      "0.03167864141084259 0.03173121791880541 0.031556039173014146\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_240 (Dense)           (None, 166)               27722     \n",
      "                                                                 \n",
      " dropout_210 (Dropout)       (None, 166)               0         \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 166)               27722     \n",
      "                                                                 \n",
      " dropout_211 (Dropout)       (None, 166)               0         \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 16)                2672      \n",
      "                                                                 \n",
      " dropout_212 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_213 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_214 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_215 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_216 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 166)               2822      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61630 (240.74 KB)\n",
      "Trainable params: 61630 (240.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "59/59 [==============================] - 3s 8ms/step - loss: 8.6366 - val_loss: 5.6249\n",
      "Epoch 2/25\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 4.0807 - val_loss: 2.7462\n",
      "Epoch 3/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.5185 - val_loss: 2.0796\n",
      "Epoch 4/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.0236 - val_loss: 1.7804\n",
      "Epoch 5/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7656 - val_loss: 1.6029\n",
      "Epoch 6/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6144 - val_loss: 1.4943\n",
      "Epoch 7/25\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.5205 - val_loss: 1.4218\n",
      "Epoch 8/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4460 - val_loss: 1.3705\n",
      "Epoch 9/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4082 - val_loss: 1.3315\n",
      "Epoch 10/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3735 - val_loss: 1.3006\n",
      "Epoch 11/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3421 - val_loss: 1.2756\n",
      "Epoch 12/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3201 - val_loss: 1.2545\n",
      "Epoch 13/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2979 - val_loss: 1.2364\n",
      "Epoch 14/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2853 - val_loss: 1.2209\n",
      "Epoch 15/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2664 - val_loss: 1.2075\n",
      "Epoch 16/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2563 - val_loss: 1.1961\n",
      "Epoch 17/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2418 - val_loss: 1.1854\n",
      "Epoch 18/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2311 - val_loss: 1.1753\n",
      "Epoch 19/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2244 - val_loss: 1.1668\n",
      "Epoch 20/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2129 - val_loss: 1.1592\n",
      "Epoch 21/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2048 - val_loss: 1.1523\n",
      "Epoch 22/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1961 - val_loss: 1.1453\n",
      "Epoch 23/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1913 - val_loss: 1.1401\n",
      "Epoch 24/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1850 - val_loss: 1.1338\n",
      "Epoch 25/25\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1798 - val_loss: 1.1282\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on musk...\n",
      "0.03167864141084259 0.03173121791880541 0.031556039173014146\n",
      "Running iForest on optdigits...\n",
      "0.028757668711656442 0.02875924404272802 0.02875399361022364\n",
      "Running AutoEncoder on optdigits...\n",
      "0.028757668711656442 0.02875924404272802 0.02875399361022364\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_248 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_217 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_218 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout_219 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_220 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_221 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_222 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_223 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 64)                1088      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11140 (43.52 KB)\n",
      "Trainable params: 11140 (43.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "100/100 [==============================] - 3s 6ms/step - loss: 5.4373 - val_loss: 3.1500\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8566 - val_loss: 1.8622\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0438 - val_loss: 1.4909\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7077 - val_loss: 1.3108\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.5191 - val_loss: 1.2106\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.3997 - val_loss: 1.1446\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3215 - val_loss: 1.1010\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2649 - val_loss: 1.0711\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2252 - val_loss: 1.0486\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1951 - val_loss: 1.0306\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1698 - val_loss: 1.0164\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1498 - val_loss: 1.0047\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1340 - val_loss: 0.9949\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1209 - val_loss: 0.9859\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1097 - val_loss: 0.9788\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1005 - val_loss: 0.9722\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0922 - val_loss: 0.9660\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0842 - val_loss: 0.9609\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0783 - val_loss: 0.9561\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0726 - val_loss: 0.9518\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0676 - val_loss: 0.9478\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0628 - val_loss: 0.9440\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0597 - val_loss: 0.9408\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0562 - val_loss: 0.9375\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0533 - val_loss: 0.9347\n",
      "111/111 [==============================] - 0s 1ms/step\n",
      "49/49 [==============================] - 0s 938us/step\n",
      "49/49 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on optdigits...\n",
      "0.028757668711656442 0.02875924404272802 0.02875399361022364\n",
      "Running iForest on PageBlocks...\n",
      "0.09456703133691823 0.09456953642384106 0.09456118665018541\n",
      "Running AutoEncoder on PageBlocks...\n",
      "0.09456703133691823 0.09456953642384106 0.09456118665018541\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_256 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dropout_224 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dropout_225 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 16)                176       \n",
      "                                                                 \n",
      " dropout_226 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_227 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_228 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_229 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_230 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1258 (4.91 KB)\n",
      "Trainable params: 1258 (4.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "97/97 [==============================] - 3s 6ms/step - loss: 1.9142 - val_loss: 1.7100\n",
      "Epoch 2/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.5162 - val_loss: 1.4418\n",
      "Epoch 3/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.3274 - val_loss: 1.3201\n",
      "Epoch 4/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.2418 - val_loss: 1.2559\n",
      "Epoch 5/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.1869 - val_loss: 1.2150\n",
      "Epoch 6/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.1569 - val_loss: 1.1899\n",
      "Epoch 7/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.1329 - val_loss: 1.1717\n",
      "Epoch 8/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.1122 - val_loss: 1.1569\n",
      "Epoch 9/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.1010 - val_loss: 1.1449\n",
      "Epoch 10/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.0853 - val_loss: 1.1346\n",
      "Epoch 11/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.0781 - val_loss: 1.1201\n",
      "Epoch 12/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.0648 - val_loss: 1.0942\n",
      "Epoch 13/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.0535 - val_loss: 1.0810\n",
      "Epoch 14/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.0367 - val_loss: 1.0628\n",
      "Epoch 15/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.0187 - val_loss: 1.0495\n",
      "Epoch 16/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.0106 - val_loss: 1.0366\n",
      "Epoch 17/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.0048 - val_loss: 1.0305\n",
      "Epoch 18/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0187\n",
      "Epoch 19/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.9813 - val_loss: 1.0074\n",
      "Epoch 20/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.9745 - val_loss: 1.0024\n",
      "Epoch 21/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.9728 - val_loss: 0.9974\n",
      "Epoch 22/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.9679 - val_loss: 0.9918\n",
      "Epoch 23/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.9609 - val_loss: 0.9923\n",
      "Epoch 24/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.9524 - val_loss: 0.9898\n",
      "Epoch 25/25\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.9532 - val_loss: 0.9892\n",
      "107/107 [==============================] - 0s 1ms/step\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on PageBlocks...\n",
      "0.09456703133691823 0.09456953642384106 0.09456118665018541\n",
      "Running iForest on pendigits...\n",
      "0.022707423580786028 0.022665834892909128 0.022804463852498787\n",
      "Running AutoEncoder on pendigits...\n",
      "0.022707423580786028 0.022665834892909128 0.022804463852498787\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_264 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_231 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_265 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_232 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_233 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_235 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_236 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_237 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1780 (6.95 KB)\n",
      "Trainable params: 1780 (6.95 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "133/133 [==============================] - 3s 3ms/step - loss: 2.3396 - val_loss: 1.7352\n",
      "Epoch 2/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.5118 - val_loss: 1.3717\n",
      "Epoch 3/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2863 - val_loss: 1.2441\n",
      "Epoch 4/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1933 - val_loss: 1.1837\n",
      "Epoch 5/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1471 - val_loss: 1.1500\n",
      "Epoch 6/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1199 - val_loss: 1.1283\n",
      "Epoch 7/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1022 - val_loss: 1.1134\n",
      "Epoch 8/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0878 - val_loss: 1.1024\n",
      "Epoch 9/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0788 - val_loss: 1.0937\n",
      "Epoch 10/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0706 - val_loss: 1.0867\n",
      "Epoch 11/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0644 - val_loss: 1.0809\n",
      "Epoch 12/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0588 - val_loss: 1.0759\n",
      "Epoch 13/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0540 - val_loss: 1.0717\n",
      "Epoch 14/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0501 - val_loss: 1.0680\n",
      "Epoch 15/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0465 - val_loss: 1.0647\n",
      "Epoch 16/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0429 - val_loss: 1.0618\n",
      "Epoch 17/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0400 - val_loss: 1.0592\n",
      "Epoch 18/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0373 - val_loss: 1.0568\n",
      "Epoch 19/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0349 - val_loss: 1.0547\n",
      "Epoch 20/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0328 - val_loss: 1.0527\n",
      "Epoch 21/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0307 - val_loss: 1.0508\n",
      "Epoch 22/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0290 - val_loss: 1.0491\n",
      "Epoch 23/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0273 - val_loss: 1.0476\n",
      "Epoch 24/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0253 - val_loss: 1.0461\n",
      "Epoch 25/25\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0242 - val_loss: 1.0447\n",
      "147/147 [==============================] - 0s 740us/step\n",
      "65/65 [==============================] - 0s 803us/step\n",
      "65/65 [==============================] - 0s 756us/step\n",
      "Running LUNAR on pendigits...\n",
      "0.022707423580786028 0.022665834892909128 0.022804463852498787\n",
      "Running iForest on Pima...\n",
      "0.3489583333333333 0.34823091247672255 0.35064935064935066\n",
      "Running AutoEncoder on Pima...\n",
      "0.3489583333333333 0.34823091247672255 0.35064935064935066\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_272 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout_238 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout_239 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 16)                144       \n",
      "                                                                 \n",
      " dropout_240 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_241 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_242 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_243 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_244 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1116 (4.36 KB)\n",
      "Trainable params: 1116 (4.36 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "10/10 [==============================] - 2s 28ms/step - loss: 2.6083 - val_loss: 2.0113\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3993 - val_loss: 1.9012\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2385 - val_loss: 1.8184\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.1492 - val_loss: 1.7511\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0355 - val_loss: 1.6952\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9705 - val_loss: 1.6455\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8989 - val_loss: 1.6014\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8400 - val_loss: 1.5595\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7835 - val_loss: 1.5195\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7450 - val_loss: 1.4829\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6726 - val_loss: 1.4502\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6411 - val_loss: 1.4209\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6070 - val_loss: 1.3944\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5740 - val_loss: 1.3709\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5508 - val_loss: 1.3491\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5234 - val_loss: 1.3287\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4902 - val_loss: 1.3105\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4743 - val_loss: 1.2931\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4505 - val_loss: 1.2772\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4384 - val_loss: 1.2625\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.4177 - val_loss: 1.2480\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3904 - val_loss: 1.2351\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3836 - val_loss: 1.2228\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3737 - val_loss: 1.2113\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3597 - val_loss: 1.2007\n",
      "11/11 [==============================] - 0s 872us/step\n",
      "8/8 [==============================] - 0s 912us/step\n",
      "8/8 [==============================] - 0s 943us/step\n",
      "Running LUNAR on Pima...\n",
      "0.3489583333333333 0.34823091247672255 0.35064935064935066\n",
      "Running iForest on satimage-2...\n",
      "0.0122350508357746 0.012309207287050714 0.012062033314187249\n",
      "Running AutoEncoder on satimage-2...\n",
      "0.0122350508357746 0.012309207287050714 0.012062033314187249\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_280 (Dense)           (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_245 (Dropout)       (None, 36)                0         \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 36)                1332      \n",
      "                                                                 \n",
      " dropout_246 (Dropout)       (None, 36)                0         \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 16)                592       \n",
      "                                                                 \n",
      " dropout_247 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_248 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_249 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_250 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_251 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 36)                612       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4560 (17.81 KB)\n",
      "Trainable params: 4560 (17.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "113/113 [==============================] - 3s 3ms/step - loss: 2.7181 - val_loss: 1.9026\n",
      "Epoch 2/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.6226 - val_loss: 1.4329\n",
      "Epoch 3/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.3728 - val_loss: 1.2896\n",
      "Epoch 4/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.2699 - val_loss: 1.2136\n",
      "Epoch 5/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.2117 - val_loss: 1.1680\n",
      "Epoch 6/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.1747 - val_loss: 1.1386\n",
      "Epoch 7/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.1509 - val_loss: 1.1168\n",
      "Epoch 8/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.1344 - val_loss: 1.1017\n",
      "Epoch 9/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.1210 - val_loss: 1.0891\n",
      "Epoch 10/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.1113 - val_loss: 1.0791\n",
      "Epoch 11/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.1011 - val_loss: 1.0711\n",
      "Epoch 12/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0942 - val_loss: 1.0635\n",
      "Epoch 13/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0876 - val_loss: 1.0573\n",
      "Epoch 14/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0818 - val_loss: 1.0515\n",
      "Epoch 15/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0763 - val_loss: 1.0467\n",
      "Epoch 16/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0727 - val_loss: 1.0421\n",
      "Epoch 17/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0695 - val_loss: 1.0384\n",
      "Epoch 18/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0651 - val_loss: 1.0345\n",
      "Epoch 19/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0627 - val_loss: 1.0314\n",
      "Epoch 20/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0581 - val_loss: 1.0284\n",
      "Epoch 21/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0569 - val_loss: 1.0256\n",
      "Epoch 22/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0545 - val_loss: 1.0229\n",
      "Epoch 23/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0521 - val_loss: 1.0207\n",
      "Epoch 24/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0494 - val_loss: 1.0182\n",
      "Epoch 25/25\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 1.0479 - val_loss: 1.0163\n",
      "126/126 [==============================] - 0s 832us/step\n",
      "55/55 [==============================] - 0s 759us/step\n",
      "55/55 [==============================] - 0s 806us/step\n",
      "Running LUNAR on satimage-2...\n",
      "0.0122350508357746 0.012309207287050714 0.012062033314187249\n",
      "Running iForest on SpamBase...\n",
      "0.39909674352270025 0.399116847826087 0.3990498812351544\n",
      "Running AutoEncoder on SpamBase...\n",
      "0.39909674352270025 0.399116847826087 0.3990498812351544\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_288 (Dense)           (None, 57)                3306      \n",
      "                                                                 \n",
      " dropout_252 (Dropout)       (None, 57)                0         \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 57)                3306      \n",
      "                                                                 \n",
      " dropout_253 (Dropout)       (None, 57)                0         \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 16)                928       \n",
      "                                                                 \n",
      " dropout_254 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_255 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_256 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_257 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_258 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 57)                969       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9201 (35.94 KB)\n",
      "Trainable params: 9201 (35.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 3s 10ms/step - loss: 6.3442 - val_loss: 4.4779\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4.4682 - val_loss: 3.4149\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 3.4246 - val_loss: 2.5383\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 2.7450 - val_loss: 2.1192\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 2.3502 - val_loss: 1.8563\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 2.1023 - val_loss: 1.6754\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.9099 - val_loss: 1.5437\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.7626 - val_loss: 1.4443\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.6510 - val_loss: 1.3666\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.5618 - val_loss: 1.3068\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.4893 - val_loss: 1.2591\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.4315 - val_loss: 1.2211\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.3827 - val_loss: 1.1911\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.3419 - val_loss: 1.1661\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.3092 - val_loss: 1.1451\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.2806 - val_loss: 1.1280\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.2612 - val_loss: 1.1134\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.2360 - val_loss: 1.1007\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.2202 - val_loss: 1.0904\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.2038 - val_loss: 1.0807\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.1897 - val_loss: 1.0725\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.1773 - val_loss: 1.0653\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.1692 - val_loss: 1.0590\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.1591 - val_loss: 1.0531\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.1512 - val_loss: 1.0476\n",
      "56/56 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "40/40 [==============================] - 0s 965us/step\n",
      "Running LUNAR on SpamBase...\n",
      "0.39909674352270025 0.399116847826087 0.3990498812351544\n",
      "Running iForest on speech...\n",
      "0.016549104720564298 0.016666666666666666 0.0162748643761302\n",
      "Running AutoEncoder on speech...\n",
      "0.016549104720564298 0.016666666666666666 0.0162748643761302\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_296 (Dense)           (None, 400)               160400    \n",
      "                                                                 \n",
      " dropout_259 (Dropout)       (None, 400)               0         \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 400)               160400    \n",
      "                                                                 \n",
      " dropout_260 (Dropout)       (None, 400)               0         \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 16)                6416      \n",
      "                                                                 \n",
      " dropout_261 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_262 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_300 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_263 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_264 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_265 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 400)               6800      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 334708 (1.28 MB)\n",
      "Trainable params: 334708 (1.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "72/72 [==============================] - 3s 9ms/step - loss: 25.9387 - val_loss: 18.4710\n",
      "Epoch 2/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 10.7816 - val_loss: 7.8623\n",
      "Epoch 3/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 5.1575 - val_loss: 4.9811\n",
      "Epoch 4/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 3.2547 - val_loss: 3.5216\n",
      "Epoch 5/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 2.3925 - val_loss: 2.7311\n",
      "Epoch 6/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.9740 - val_loss: 2.2844\n",
      "Epoch 7/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.7479 - val_loss: 2.0157\n",
      "Epoch 8/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.6317 - val_loss: 1.8419\n",
      "Epoch 9/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.5505 - val_loss: 1.7259\n",
      "Epoch 10/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.4978 - val_loss: 1.6431\n",
      "Epoch 11/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.4495 - val_loss: 1.5801\n",
      "Epoch 12/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.4169 - val_loss: 1.5330\n",
      "Epoch 13/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.3924 - val_loss: 1.4951\n",
      "Epoch 14/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.3702 - val_loss: 1.4652\n",
      "Epoch 15/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.3487 - val_loss: 1.4396\n",
      "Epoch 16/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.3284 - val_loss: 1.4173\n",
      "Epoch 17/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.3120 - val_loss: 1.3988\n",
      "Epoch 18/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.3053 - val_loss: 1.3844\n",
      "Epoch 19/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.2849 - val_loss: 1.3684\n",
      "Epoch 20/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.2787 - val_loss: 1.3585\n",
      "Epoch 21/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.2632 - val_loss: 1.3460\n",
      "Epoch 22/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.2576 - val_loss: 1.3382\n",
      "Epoch 23/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.2475 - val_loss: 1.3279\n",
      "Epoch 24/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.2420 - val_loss: 1.3204\n",
      "Epoch 25/25\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.2302 - val_loss: 1.3123\n",
      "80/80 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "35/35 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on speech...\n",
      "0.016549104720564298 0.016666666666666666 0.0162748643761302\n",
      "Running iForest on Wilt...\n",
      "0.05333056650757419 0.05336495701156241 0.05325034578146611\n",
      "Running AutoEncoder on Wilt...\n",
      "0.05333056650757419 0.05336495701156241 0.05325034578146611\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_304 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dropout_266 (Dropout)       (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dropout_267 (Dropout)       (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 16)                96        \n",
      "                                                                 \n",
      " dropout_268 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_269 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_270 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_271 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_310 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_272 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 933 (3.64 KB)\n",
      "Trainable params: 933 (3.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "90/90 [==============================] - 4s 6ms/step - loss: 1.9021 - val_loss: 1.2945\n",
      "Epoch 2/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.5248 - val_loss: 1.1475\n",
      "Epoch 3/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.3881 - val_loss: 1.0675\n",
      "Epoch 4/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.3015 - val_loss: 1.0169\n",
      "Epoch 5/25\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.2265 - val_loss: 0.9834\n",
      "Epoch 6/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.1961 - val_loss: 0.9592\n",
      "Epoch 7/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.1799 - val_loss: 0.9410\n",
      "Epoch 8/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.1484 - val_loss: 0.9277\n",
      "Epoch 9/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.1315 - val_loss: 0.9169\n",
      "Epoch 10/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.1251 - val_loss: 0.9074\n",
      "Epoch 11/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.1092 - val_loss: 0.9001\n",
      "Epoch 12/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.1009 - val_loss: 0.8940\n",
      "Epoch 13/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0941 - val_loss: 0.8883\n",
      "Epoch 14/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0884 - val_loss: 0.8837\n",
      "Epoch 15/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0814 - val_loss: 0.8794\n",
      "Epoch 16/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0774 - val_loss: 0.8759\n",
      "Epoch 17/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0740 - val_loss: 0.8724\n",
      "Epoch 18/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 0.8696\n",
      "Epoch 19/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0671 - val_loss: 0.8668\n",
      "Epoch 20/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0651 - val_loss: 0.8645\n",
      "Epoch 21/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0614 - val_loss: 0.8620\n",
      "Epoch 22/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0570 - val_loss: 0.8600\n",
      "Epoch 23/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0565 - val_loss: 0.8586\n",
      "Epoch 24/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 0.8565\n",
      "Epoch 25/25\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.0531 - val_loss: 0.8547\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "46/46 [==============================] - 0s 1ms/step\n",
      "46/46 [==============================] - 0s 989us/step\n",
      "Running LUNAR on Wilt...\n",
      "0.05333056650757419 0.05336495701156241 0.05325034578146611\n",
      "Running iForest on Cardiotocography...\n",
      "0.22043519394512773 0.22041920216362407 0.2204724409448819\n",
      "Running AutoEncoder on Cardiotocography...\n",
      "0.22043519394512773 0.22041920216362407 0.2204724409448819\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_312 (Dense)           (None, 21)                462       \n",
      "                                                                 \n",
      " dropout_273 (Dropout)       (None, 21)                0         \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 21)                462       \n",
      "                                                                 \n",
      " dropout_274 (Dropout)       (None, 21)                0         \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dropout_275 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_276 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 4)                 68        \n",
      "                                                                 \n",
      " dropout_277 (Dropout)       (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 16)                80        \n",
      "                                                                 \n",
      " dropout_278 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_279 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 21)                357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2325 (9.08 KB)\n",
      "Trainable params: 2325 (9.08 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "33/33 [==============================] - 3s 12ms/step - loss: 3.4563 - val_loss: 2.7181\n",
      "Epoch 2/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.7134 - val_loss: 2.2775\n",
      "Epoch 3/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.3014 - val_loss: 1.9550\n",
      "Epoch 4/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 2.0144 - val_loss: 1.7229\n",
      "Epoch 5/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.8083 - val_loss: 1.5715\n",
      "Epoch 6/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.6839 - val_loss: 1.4653\n",
      "Epoch 7/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5818 - val_loss: 1.3875\n",
      "Epoch 8/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.5068 - val_loss: 1.3271\n",
      "Epoch 9/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4535 - val_loss: 1.2795\n",
      "Epoch 10/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4027 - val_loss: 1.2422\n",
      "Epoch 11/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3569 - val_loss: 1.2102\n",
      "Epoch 12/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.3247 - val_loss: 1.1848\n",
      "Epoch 13/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2996 - val_loss: 1.1634\n",
      "Epoch 14/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2770 - val_loss: 1.1441\n",
      "Epoch 15/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2548 - val_loss: 1.1288\n",
      "Epoch 16/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2397 - val_loss: 1.1147\n",
      "Epoch 17/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2250 - val_loss: 1.1028\n",
      "Epoch 18/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.2120 - val_loss: 1.0921\n",
      "Epoch 19/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1983 - val_loss: 1.0827\n",
      "Epoch 20/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1926 - val_loss: 1.0745\n",
      "Epoch 21/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1812 - val_loss: 1.0671\n",
      "Epoch 22/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1728 - val_loss: 1.0604\n",
      "Epoch 23/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1655 - val_loss: 1.0542\n",
      "Epoch 24/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1570 - val_loss: 1.0490\n",
      "Epoch 25/25\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.1516 - val_loss: 1.0442\n",
      "37/37 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "Running LUNAR on Cardiotocography...\n",
      "0.22043519394512773 0.22041920216362407 0.2204724409448819\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th># Samples</th>\n",
       "      <th># Features</th>\n",
       "      <th>Anomaly Ratio</th>\n",
       "      <th>iForest Precision</th>\n",
       "      <th>iForest AUC</th>\n",
       "      <th>iForest Accuracy</th>\n",
       "      <th>iForest Recall</th>\n",
       "      <th>iForest F1 Score</th>\n",
       "      <th>iForest Fit Time</th>\n",
       "      <th>...</th>\n",
       "      <th>AutoEncoder F1 Score</th>\n",
       "      <th>AutoEncoder Fit Time</th>\n",
       "      <th>AutoEncoder Score Time</th>\n",
       "      <th>LUNAR Precision</th>\n",
       "      <th>LUNAR AUC</th>\n",
       "      <th>LUNAR Accuracy</th>\n",
       "      <th>LUNAR Recall</th>\n",
       "      <th>LUNAR F1 Score</th>\n",
       "      <th>LUNAR Fit Time</th>\n",
       "      <th>LUNAR Score Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fault</td>\n",
       "      <td>1941</td>\n",
       "      <td>27</td>\n",
       "      <td>34.672849</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>0.5508</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4623</td>\n",
       "      <td>4.5276</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.6224</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>3.7967</td>\n",
       "      <td>0.0205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glass</td>\n",
       "      <td>214</td>\n",
       "      <td>7</td>\n",
       "      <td>4.205607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7527</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8452</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8118</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7724</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hepatitis</td>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>3.6008</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5849</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InternetAds</td>\n",
       "      <td>1966</td>\n",
       "      <td>1555</td>\n",
       "      <td>18.71821</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4695</td>\n",
       "      <td>23.5302</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.6458</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>0.6019</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.0515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ionosphere</td>\n",
       "      <td>351</td>\n",
       "      <td>32</td>\n",
       "      <td>35.897436</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.9211</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7048</td>\n",
       "      <td>3.0276</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.8113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>1.5153</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>landsat</td>\n",
       "      <td>6435</td>\n",
       "      <td>36</td>\n",
       "      <td>20.714841</td>\n",
       "      <td>0.3263</td>\n",
       "      <td>0.5947</td>\n",
       "      <td>0.7074</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.3543</td>\n",
       "      <td>0.156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>7.5646</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.5312</td>\n",
       "      <td>0.7902</td>\n",
       "      <td>0.8058</td>\n",
       "      <td>0.5325</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>11.4915</td>\n",
       "      <td>0.0244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>letter</td>\n",
       "      <td>1600</td>\n",
       "      <td>32</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.6228</td>\n",
       "      <td>0.8583</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>4.0131</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>4.1365</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>magic</td>\n",
       "      <td>19020</td>\n",
       "      <td>10</td>\n",
       "      <td>35.162986</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.6047</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>12.8929</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.8589</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>0.7453</td>\n",
       "      <td>0.7117</td>\n",
       "      <td>28.2592</td>\n",
       "      <td>0.3528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mammography</td>\n",
       "      <td>11183</td>\n",
       "      <td>6</td>\n",
       "      <td>2.324958</td>\n",
       "      <td>0.2843</td>\n",
       "      <td>0.8774</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.3718</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2919</td>\n",
       "      <td>11.1621</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.3718</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>32.4583</td>\n",
       "      <td>0.1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mnist</td>\n",
       "      <td>7603</td>\n",
       "      <td>100</td>\n",
       "      <td>9.206892</td>\n",
       "      <td>0.3742</td>\n",
       "      <td>0.8709</td>\n",
       "      <td>0.8746</td>\n",
       "      <td>0.5381</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5557</td>\n",
       "      <td>12.9826</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.6182</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>0.6326</td>\n",
       "      <td>23.2555</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>musk</td>\n",
       "      <td>3062</td>\n",
       "      <td>166</td>\n",
       "      <td>3.167864</td>\n",
       "      <td>0.2326</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>0.9434</td>\n",
       "      <td>0.3448</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>8.7037</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>10.6332</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>optdigits</td>\n",
       "      <td>5216</td>\n",
       "      <td>64</td>\n",
       "      <td>2.875767</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.1795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.2728</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.9778</td>\n",
       "      <td>0.7928</td>\n",
       "      <td>17.1565</td>\n",
       "      <td>0.0281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PageBlocks</td>\n",
       "      <td>5393</td>\n",
       "      <td>10</td>\n",
       "      <td>9.456703</td>\n",
       "      <td>0.4142</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.1755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>9.584</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.7078</td>\n",
       "      <td>16.6376</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pendigits</td>\n",
       "      <td>6870</td>\n",
       "      <td>16</td>\n",
       "      <td>2.270742</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>8.6701</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>16.0862</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pima</td>\n",
       "      <td>768</td>\n",
       "      <td>8</td>\n",
       "      <td>34.895833</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.6279</td>\n",
       "      <td>0.5628</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>3.263</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.4105</td>\n",
       "      <td>0.7611</td>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.5756</td>\n",
       "      <td>2.2677</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>satimage-2</td>\n",
       "      <td>5803</td>\n",
       "      <td>36</td>\n",
       "      <td>1.223505</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.627</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>19.0327</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SpamBase</td>\n",
       "      <td>4207</td>\n",
       "      <td>57</td>\n",
       "      <td>39.909674</td>\n",
       "      <td>0.5847</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>0.8353</td>\n",
       "      <td>0.6879</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6815</td>\n",
       "      <td>6.6798</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.6708</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>9.2823</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>speech</td>\n",
       "      <td>3686</td>\n",
       "      <td>400</td>\n",
       "      <td>1.65491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4001</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>12.3529</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.5649</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>12.7193</td>\n",
       "      <td>0.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wilt</td>\n",
       "      <td>4819</td>\n",
       "      <td>5</td>\n",
       "      <td>5.333057</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.5122</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3345</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>15.5379</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cardiotocography</td>\n",
       "      <td>2114</td>\n",
       "      <td>21</td>\n",
       "      <td>22.043519</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.7512</td>\n",
       "      <td>0.6714</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.6059</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.5781</td>\n",
       "      <td>6.6837</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dataset # Samples # Features Anomaly Ratio iForest Precision  \\\n",
       "0              fault      1941         27     34.672849            0.4815   \n",
       "1              glass       214          7      4.205607               0.0   \n",
       "2          Hepatitis        80         19         16.25               0.0   \n",
       "3        InternetAds      1966       1555      18.71821              0.23   \n",
       "4         Ionosphere       351         32     35.897436            0.5645   \n",
       "5            landsat      6435         36     20.714841            0.3263   \n",
       "6             letter      1600         32          6.25            0.0682   \n",
       "7              magic     19020         10     35.162986            0.5162   \n",
       "8        mammography     11183          6      2.324958            0.2843   \n",
       "9              mnist      7603        100      9.206892            0.3742   \n",
       "10              musk      3062        166      3.167864            0.2326   \n",
       "11         optdigits      5216         64      2.875767              0.05   \n",
       "12        PageBlocks      5393         10      9.456703            0.4142   \n",
       "13         pendigits      6870         16      2.270742            0.2892   \n",
       "14              Pima       768          8     34.895833            0.4167   \n",
       "15        satimage-2      5803         36      1.223505               0.5   \n",
       "16          SpamBase      4207         57     39.909674            0.5847   \n",
       "17            speech      3686        400       1.65491               0.0   \n",
       "18              Wilt      4819          5      5.333057            0.0308   \n",
       "19  Cardiotocography      2114         21     22.043519            0.4563   \n",
       "\n",
       "   iForest AUC iForest Accuracy iForest Recall iForest F1 Score  \\\n",
       "0       0.6933           0.6364         0.6436           0.5508   \n",
       "1       0.7527           0.9231            0.0              0.0   \n",
       "2         0.85           0.8333            0.0              0.0   \n",
       "3        0.512            0.722         0.2091            0.219   \n",
       "4       0.8862            0.717         0.9211              0.7   \n",
       "5       0.5947           0.7074         0.3875           0.3543   \n",
       "6       0.6228           0.8583            0.1           0.0811   \n",
       "7        0.762           0.6646         0.7298           0.6047   \n",
       "8       0.8774           0.9636         0.3718           0.3222   \n",
       "9       0.8709           0.8746         0.5381           0.4414   \n",
       "10      0.9344           0.9434         0.3448           0.2778   \n",
       "11      0.7777           0.9482         0.0444           0.0471   \n",
       "12      0.9227            0.877         0.7255           0.5273   \n",
       "13      0.9495           0.9602         0.5106           0.3692   \n",
       "14      0.6279           0.5628         0.6173           0.4975   \n",
       "15      0.9973           0.9879         0.9524           0.6557   \n",
       "16      0.8198           0.6975         0.8353           0.6879   \n",
       "17      0.4001            0.972            0.0              0.0   \n",
       "18      0.5122           0.9046          0.026           0.0282   \n",
       "19       0.809           0.7512         0.6714           0.5434   \n",
       "\n",
       "   iForest Fit Time  ... AutoEncoder F1 Score AutoEncoder Fit Time  \\\n",
       "0            0.0945  ...               0.4623               4.5276   \n",
       "1            0.1025  ...                  0.0               2.8452   \n",
       "2            0.0784  ...               0.4444               3.6008   \n",
       "3            0.1215  ...               0.4695              23.5302   \n",
       "4            0.1126  ...               0.7048               3.0276   \n",
       "5             0.156  ...               0.2236               7.5646   \n",
       "6            0.1237  ...               0.0333               4.0131   \n",
       "7            0.1902  ...               0.5401              12.8929   \n",
       "8            0.1504  ...               0.2919              11.1621   \n",
       "9            0.2438  ...               0.5557              12.9826   \n",
       "10           0.1785  ...               0.6444               8.7037   \n",
       "11           0.1795  ...                  0.0               9.2728   \n",
       "12           0.1755  ...               0.6139                9.584   \n",
       "13           0.2074  ...               0.4074               8.6701   \n",
       "14           0.1129  ...               0.5714                3.263   \n",
       "15           0.1255  ...                  0.6                8.627   \n",
       "16           0.1478  ...               0.6815               6.6798   \n",
       "17            0.172  ...               0.0526              12.3529   \n",
       "18           0.1665  ...                  0.0               9.3345   \n",
       "19           0.1652  ...                0.581               5.6059   \n",
       "\n",
       "   AutoEncoder Score Time LUNAR Precision LUNAR AUC LUNAR Accuracy  \\\n",
       "0                  0.0739          0.6224    0.8103         0.7358   \n",
       "1                   0.058             0.0    0.8118         0.8923   \n",
       "2                  0.0576             0.0       0.7         0.7917   \n",
       "3                  0.1247          0.6458    0.8222          0.861   \n",
       "4                  0.0614          0.6552    0.9834         0.8113   \n",
       "5                  0.1201          0.5312    0.7902         0.8058   \n",
       "6                  0.0723          0.5556    0.9334         0.9417   \n",
       "7                  0.2277          0.6811    0.8589         0.7878   \n",
       "8                  0.1704          0.4028    0.8728         0.9726   \n",
       "9                  0.1771          0.6182    0.9279         0.9307   \n",
       "10                  0.129          0.6591       1.0         0.9837   \n",
       "11                 0.1404          0.6667    0.9973         0.9853   \n",
       "12                 0.1756          0.7032    0.9485         0.9444   \n",
       "13                 0.1258          0.8246    0.9998         0.9951   \n",
       "14                 0.0641          0.4105    0.7611         0.5022   \n",
       "15                 0.1332          0.4545    0.9988         0.9856   \n",
       "16                 0.1334          0.6708    0.8193          0.753   \n",
       "17                 0.1363          0.0339    0.5649          0.934   \n",
       "18                 0.1527          0.0392    0.6365         0.9142   \n",
       "19                 0.1227          0.6379    0.8205         0.8299   \n",
       "\n",
       "   LUNAR Recall LUNAR F1 Score LUNAR Fit Time LUNAR Score Time  \n",
       "0         0.604         0.6131         3.7967           0.0205  \n",
       "1           0.0            0.0         1.7724            0.001  \n",
       "2           0.0            0.0         1.5849           0.0062  \n",
       "3        0.5636         0.6019         4.6549           0.0515  \n",
       "4           1.0         0.7917         1.5153           0.0071  \n",
       "5        0.5325         0.5318        11.4915           0.0244  \n",
       "6        0.3333         0.4167         4.1365            0.004  \n",
       "7        0.7453         0.7117        28.2592           0.3528  \n",
       "8        0.3718         0.3867        32.4583           0.1239  \n",
       "9        0.6476         0.6326        23.2555            0.056  \n",
       "10          1.0         0.7945        10.6332            0.019  \n",
       "11       0.9778         0.7928        17.1565           0.0281  \n",
       "12       0.7124         0.7078        16.6376            0.041  \n",
       "13          1.0         0.9038        16.0862            0.025  \n",
       "14        0.963         0.5756         2.2677            0.002  \n",
       "15       0.9524         0.6154        19.0327           0.0258  \n",
       "16        0.748         0.7073         9.2823            0.014  \n",
       "17       0.1111         0.0519        12.7193           0.0439  \n",
       "18        0.026         0.0312        15.5379            0.025  \n",
       "19       0.5286         0.5781         6.6837            0.006  \n",
       "\n",
       "[20 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (dataset, dataset_name) in enumerate(zip(datasets, dataset_names)):\n",
    "    X = dataset['X']\n",
    "    y = dataset['y']\n",
    "    anomaly_ratio = np.mean(y)*100\n",
    "\n",
    "    for name, algorithm in algorithms.items():\n",
    "        print(f\"Running {name} on {dataset_name}...\")\n",
    "        precision, auc, accuracy, f1, recall, fit_time, score_time =\\\n",
    "            evaluate_semi_supervised_algorithm_stratified(\n",
    "                algorithm, X, y)\n",
    "        results.loc[i, f'{name} Precision'] = precision\n",
    "        results.loc[i, f'{name} AUC'] = auc\n",
    "        results.loc[i, f'{name} Accuracy'] = accuracy\n",
    "        results.loc[i, f'{name} Recall'] = recall\n",
    "        results.loc[i, f'{name} F1 Score'] = f1\n",
    "        results.loc[i, f'{name} Fit Time'] = fit_time\n",
    "        results.loc[i, f'{name} Score Time'] = score_time\n",
    "\n",
    "    results.loc[i, 'Dataset'] = dataset_name\n",
    "    results.loc[i, '# Samples'] = X.shape[0]\n",
    "    results.loc[i, '# Features'] = X.shape[1]\n",
    "    results.loc[i, 'Anomaly Ratio'] = anomaly_ratio\n",
    "\n",
    "results.to_csv('results_stratified_25epoch.csv', index=False)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
